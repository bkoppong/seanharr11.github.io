<!DOCTYPE html>
<html>
<head>
    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Page Meta -->
    <title>Warehousing DbSNP, Part III: Bulk Inserting SNP Data</title>
    <meta name="description" content="Because someone else has already solved your problem." />

    <!-- Mobile Meta -->
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <!-- Brand icon -->
    <link rel="shortcut icon" href="/assets/images/favicon.ico" >

    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
    <link rel="stylesheet" type="text/css" href="/assets/css/syntax.css" />

    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!-- Ghost outputs important style and meta data with this tag -->
    <link rel="canonical" href="http://thelaziestprogrammer.com/bioinformatics/warehousing-DbSNP-Part-III-bulk-inserting-SNP-data" />
    <meta name="referrer" content="origin" />
    <link rel="next" href="/page2/" />

    <meta property="og:site_name" content="The Laziest Programmer" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Warehousing DbSNP, Part III: Bulk Inserting SNP Data" />
    <meta property="og:description" content="Because someone else has already solved your problem." />
    <meta property="og:url" content="http://thelaziestprogrammer.com/bioinformatics/warehousing-DbSNP-Part-III-bulk-inserting-SNP-data" />
    <meta property="og:image" content="http://thelaziestprogrammer.com/assets/images/tlp_logo_og.png" />

    <meta name="twitter:card" content="http://thelaziestprogrammer.com/assets/images/tlp_logo_og.png" />
    <meta name="twitter:title" content="Warehousing DbSNP, Part III: Bulk Inserting SNP Data" />
    <meta name="twitter:description" content="Because someone else has already solved your problem." />
    <meta name="twitter:url" content="http://thelaziestprogrammer.com/bioinformatics/warehousing-DbSNP-Part-III-bulk-inserting-SNP-data" />
    <meta name="twitter:image:src" content="http://thelaziestprogrammer.com/assets/images/tlp_logo_og.png" />

    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Website",
    "publisher": "The Laziest Programmer",
    "name": "Warehousing DbSNP, Part III: Bulk Inserting SNP Data",
    "url": "http://localhost:4000//bioinformatics/warehousing-DbSNP-Part-III-bulk-inserting-SNP-data",
    "image": "/assets/images/southie_fireworks.jpg",
    "description": "Because someone else has already solved your problem."
}
    </script>

    <meta name="generator" content="Jekyll 3.0.0" />
    <link rel="alternate" type="application/rss+xml" title="The Laziest Programmer" href="/feed.xml" />


</head>
<body class="home-template nav-closed">

    <!-- The blog navigation links -->
    
<div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        <li class="nav-home  nav-current" role="presentation"><a href="/">Home</a></li>
        <li class="nav-home" role="presentation"><a href="#">Topics</a>
           <ul style="padding-top:9px;padding-bottom:0px"> 
             <li class="nav-fiction " role="presentation"><a href="/tag/databases">Databases</a></li>
           </ul>     
           <ul style="padding-top:0px; padding-bottom: 0px"> 
             <li class="nav-fiction " role="presentation"><a href="/tag/web-development">Web Development</a></li>
           </ul>     
           <ul style="padding-top:0px; padding-bottom: 0px"> 
             <li class="nav-fiction " role="presentation"><a href="/tag/math-of-machine-learning">The Math of ML</a></li>
           </ul>     
           <ul style="padding-top:0px;"> 
             <li class="nav-fiction " role="presentation"><a href="/tag/bioinformatics">Bioinformatics</a></li>
           </ul>     
        </li>
        <li class="nav-about " role="presentation"><a href="/about">About This Site</a></li>
        <li class="nav-author " role="presentation"><a href="/author/sharrington">The Author</a></li>
    </ul>
    <a class="subscribe-button" href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=DH544PY7RFSLA">Donate</a>
    <a class="subscribe-button icon-feed" href="/feed.xml">Subscribe</a>
</div>
<span class="nav-cover"></span>


    <div class="site-wrapper">

        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The comment above "< default" means - insert everything in this file into -->
    <!-- the [body] of the default.hbs template, which contains our header/footer. -->

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<header class="main-header post-head " style="background-image: url(/assets/images/southie_fireworks.jpg) ">
    <nav class="main-nav  overlay  clearfix">
        <a class="blog-logo" href="/"><img src="/assets/images/tlp_logo.png" alt="Blog Logo" /></a>
        
            <a class="menu-button icon-menu" href="#"><span class="word">Menu</span></a>
        
    </nav>
</header>

<main class="content" role="main">

    <article class="post tag-test tag-content">

        <header class="post-header">
            <h1 class="post-title">Warehousing DbSNP, Part III: Bulk Inserting SNP Data</h1>
            <section class="post-meta">
            <!-- <a href='/'></a> -->

            
            <time class="post-date" datetime="2018-06-25">25 Jun 2018</time>
                <!-- [[tags prefix=" on "]] -->
                
                on
                
                    
                       <a href='/tag/bioinformatics'>Bioinformatics</a>
                    
                
                
            </section>
        </header>

        <section class="post-content">

            <h3 id="intro">Intro</h3>

<p>In <a href="warehousing-DbSNP-Part-II-parsing-RefSNP-JSON">Part II we parsed the JSON data</a> found in the DbSNP JSON download. In Part III, we will bulk-insert this data into our PostgreSQL database.</p>

<h3 id="choosing-a-postgresql-python-driver">Choosing a PostgreSQL Python Driver</h3>

<p>The list of options here is long, but I ended up choosing <a href="https://github.com/MagicStack/asyncpg">asyncpg</a> for a number of reasons:</p>

<ol>
  <li>Great support for PostgreSQL’s <code class="highlighter-rouge">COPY FROM ... STDIN</code> command.
    <ul>
      <li>Albeit this is supported in other drivers, but doesn’t have the python-object level of abstraction that I’d like.</li>
      <li>I tried adding a higher-level-of-abstraction to <code class="highlighter-rouge">psycopg2</code>’s <code class="highlighter-rouge">copy_from()</code> method, <a href="https://github.com/psycopg/psycopg2/pull/461" target="_blank">but got nowhere fast with this Pull Request</a></li>
    </ul>
  </li>
  <li>Great support for PostgreSQL’s <code class="highlighter-rouge">PREPARE</code> <a href="https://www.postgresql.org/docs/10/static/sql-prepare.html">statement</a></li>
  <li>The entire library is asynchronous, and writing <strong>lots</strong> of data to a remote datastore is a <strong>good</strong> usecase for <code class="highlighter-rouge">async</code> Python.
    <ul>
      <li><em>…we are writing to localhost in this walkthrough, so we don’t actually leverage async concurrency</em>.</li>
    </ul>
  </li>
</ol>

<h3 id="writing-to-database">Writing to Database</h3>

<p>In <a href="warehousing-DbSNP-Part-II-parsing-RefSNP-JSON#top-level-file-iteration">Part II we introduced</a> the <code class="highlighter-rouge">_load(self, parsed_data_iter)</code> method, agnostic of any implementation details. Let’s implement the method!</p>

<p>Naively, we could insert one row at a time, as each is parsed, as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">async</span> <span class="k">def</span> <span class="nf">_load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">parsed_data_iter</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">RefSnpCopyFromData</span><span class="p">]):</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">await</span> <span class="n">asyncpg</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">database</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">database_name</span><span class="p">,</span>
                                 <span class="n">user</span><span class="o">=</span><span class="s">"SeanH"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">copy_from_data</span> <span class="ow">in</span> <span class="n">parsed_data_iter</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">table_name</span> <span class="ow">in</span> <span class="n">copy_from_data</span><span class="o">.</span><span class="n">_fields</span><span class="p">:</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">copy_from_data</span><span class="p">,</span> <span class="n">table_name</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
                <span class="n">await</span> <span class="n">conn</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
                    <span class="n">f</span><span class="s">"INSERT INTO {table_name} "</span>
                    <span class="s">"{row._fields} "</span>
                    <span class="s">"VALUES ($1, $2)"</span><span class="p">,</span> <span class="o">*</span><span class="n">row</span><span class="p">)</span>
</code></pre></div></div>

<p>But we can do better than this!</p>

<p>PostgreSQL has <strong>the best</strong> (<em>strong opinion loosely held</em>) BULK INSERT method available. I make this claim having written <a href="https://github.com/seanharr11/etlalchemy">ETLAlchemy</a>: a library facilitating full-database (schema and data) migrations between any database supported by SQLAlchemy Core.</p>

<p>To properly bulk-insert, we need a buffer to continuously aggregate our data, and bulk-insert/dump buffer to the database intermittently when we hit our threshold.</p>

<p>Let’s try this:</p>

<p><a href="https://github.com/seanharr11/snip_warehouse/blob/68da728ccf45e156074ccf82a503cd2bdc2c7246/snip_warehouse/snip_loader.py#L73">Github Link</a></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">async</span> <span class="k">def</span> <span class="nf">_load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parsed_data_iter</span><span class="p">):</span>
        <span class="n">conn</span> <span class="o">=</span> <span class="n">await</span> <span class="n">asyncpg</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
            <span class="n">database</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">database_name</span><span class="p">,</span> <span class="n">user</span><span class="o">=</span><span class="s">"SeanH"</span><span class="p">)</span>
        <span class="n">await</span> <span class="n">conn</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="s">"SET session_replication_role to 'replica'"</span><span class="p">)</span>
            <span class="c"># This should stop FK checks...</span>
        <span class="n">table_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">table_name</span>
                       <span class="k">for</span> <span class="n">table_name</span> <span class="ow">in</span> <span class="n">RefSnpCopyFromData</span><span class="o">.</span><span class="n">_fields</span><span class="p">]</span>
        <span class="n">row_buff_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">table_name</span><span class="p">:</span> <span class="p">[]</span>
                         <span class="k">for</span> <span class="n">table_name</span> <span class="ow">in</span> <span class="n">table_names</span><span class="p">}</span>
        <span class="n">buff_size</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">copy_from_data</span> <span class="ow">in</span> <span class="n">parsed_data_iter</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">table_name</span> <span class="ow">in</span> <span class="n">table_names</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">copy_from_row</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">copy_from_data</span><span class="p">,</span>
                                             <span class="n">table_name</span><span class="p">):</span>
                    <span class="n">row_buff_dict</span><span class="p">[</span><span class="n">table_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">copy_from_row</span><span class="p">)</span>
            <span class="n">buff_size</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">buff_size</span> <span class="o">%</span> <span class="mi">5000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c"># Dump</span>
                <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"Dumping (SNPs Processed: {buff_size})"</span><span class="p">)</span>
                <span class="n">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dump_buffer</span><span class="p">(</span><span class="n">row_buff_dict</span><span class="p">,</span> <span class="n">conn</span><span class="p">)</span>
                <span class="n">row_buff_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">table_name</span><span class="p">:</span> <span class="p">[]</span>
                                 <span class="k">for</span> <span class="n">table_name</span> <span class="ow">in</span> <span class="n">table_names</span><span class="p">}</span>
                <span class="k">print</span><span class="p">(</span><span class="s">"Done."</span><span class="p">)</span>
        <span class="n">await</span> <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">async</span> <span class="k">def</span> <span class="nf">_dump_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">row_buff_dict</span><span class="p">,</span> <span class="n">conn</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">table_name</span> <span class="ow">in</span> <span class="n">row_buff_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">records</span> <span class="o">=</span> <span class="n">row_buff_dict</span><span class="p">[</span><span class="n">table_name</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">records</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">await</span> <span class="n">conn</span><span class="o">.</span><span class="n">copy_records_to_table</span><span class="p">(</span>
                <span class="n">table_name</span><span class="p">,</span>
                <span class="n">records</span><span class="o">=</span><span class="n">records</span><span class="p">,</span>
                <span class="n">columns</span><span class="o">=</span><span class="n">records</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_fields</span><span class="p">)</span>
</code></pre></div></div>

<p>As each <code class="highlighter-rouge">RefSnpCopyFromData</code> object becomes available, we add its contents to our buffer. We apply the KISS principle, implementing our buffer as a <code class="highlighter-rouge">dict</code>, mapping <code class="highlighter-rouge">table_name</code> -&gt; <code class="highlighter-rouge">List[namedtuple]</code>.</p>

<blockquote>
  <p><strong>Note:</strong> <em>For simplicity’s sake, rather than tracking the memory footprint of our buffer, we are just tracking the # of <code class="highlighter-rouge">RefSNPs</code> processed.</em></p>
</blockquote>

<p>When we hit our <code class="highlighter-rouge">buff_size</code>, in this case <code class="highlighter-rouge">5000</code>, we leverage <code class="highlighter-rouge">asyncpg</code>’s <code class="highlighter-rouge">copy_records_to_table()</code> method to write to the database, and free up memory by re-initializing our buffer.</p>

<h3 id="the-top-level-method-revisited">The Top-level Method: Revisited</h3>

<p>Remember our <code class="highlighter-rouge">load_ref_snps()</code> method? Recall that our <code class="highlighter-rouge">_load()</code> method is asynchronous, this means we will have to run it with a Python <code class="highlighter-rouge">asyncio</code> loop. We update our method as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">load_ref_snps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dbsnp_filename</span><span class="p">,</span> <span class="n">chromosome</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chromosome</span> <span class="o">=</span> <span class="n">chromosome</span>
        <span class="n">loop</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">get_event_loop</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">dbsnp_filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">gzip_fp</span><span class="p">:</span>
            <span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_generate_parsed_data</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">gzip_fp</span><span class="p">)))</span>
</code></pre></div></div>

<blockquote>
  <p><strong>Note:</strong> <em>It’s worth noting that we get NOTHING from running the <code class="highlighter-rouge">_load()</code> method in an <code class="highlighter-rouge">asyncio</code> loop. We are only using asyncio because the <code class="highlighter-rouge">asyncpg</code> library requires us to do so, that’s the only reason!</em></p>
</blockquote>

<p><em>In the future, this also opens up the door to asynchronously download/stream each <code class="highlighter-rouge">refsnp-chr*.json.gz</code> file,  while we concurrently parse and insert the data into the database. This would be a <strong>great</strong> optimization, but is outside our scope!</em></p>

<h3 id="the-top-level-method-multiprocessed">The Top-level Method: Multiprocessed</h3>

<p>Our current implementation presents a great opportunity to leverage Python’s <code class="highlighter-rouge">multiprocessing</code> library, without any design changes. We just simply “hand-off” the streaming and parsing of our JSON to a pool of child processes, while our parent process accumulates our data buffer, eventually dumping to our database.</p>

<p>On my 8-core 2016 Macbook Pro, making the change from non-parallelized code to parallelized code reduces the run time from <strong>1 hour and 3 minutes</strong> down to <strong>20 minutes</strong>: a <strong>300%</strong> performance increase. Not too shabby…</p>

<p><a href="https://github.com/seanharr11/snip_warehouse/blob/68da728ccf45e156074ccf82a503cd2bdc2c7246/snip_warehouse/snip_loader.py#L59">Github Link</a></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">load_ref_snps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dbsnp_filename</span><span class="p">,</span> <span class="n">chromosome</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chromosome</span> <span class="o">=</span> <span class="n">chromosome</span>
        <span class="n">num_processes</span> <span class="o">=</span> <span class="n">cpu_count</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"Found '{num_processes}' CPUs"</span><span class="p">)</span>
        <span class="n">loop</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">get_event_loop</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="n">num_processes</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">dbsnp_filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">gzip_fp</span><span class="p">:</span>
                <span class="n">copy_from_data_iter</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">imap_unordered</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_generate_parsed_data</span><span class="p">,</span>
                    <span class="n">gzip_fp</span><span class="p">,</span>
                    <span class="mi">1024</span><span class="p">)</span>  <span class="c"># chunksize</span>
                <span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">(</span><span class="n">copy_from_data_iter</span><span class="p">))</span>
</code></pre></div></div>

<p>That’s it! Our <code class="highlighter-rouge">Pool</code> object manages each child process by handing off lines from <code class="highlighter-rouge">gzip_fp</code> to each process, returning an Iterator of <code class="highlighter-rouge">RefSnpCopyFromData</code> objects which is handed off to <code class="highlighter-rouge">load()</code>, satisfying the methods contract!</p>

<blockquote>
  <p><strong>Note:</strong> <em>It is not by coincidence that we were able to easily parallelize our application, nor was it by some perfect design. In my experience, it is a combination of</em>:</p>
</blockquote>

<ol>
  <li>A desire to design and produce small, concise pieces of code, encapsulated in classes and methods with well-defined interfaces.</li>
  <li>Many, many iterations. (<em>I went through 3 full refactors while putting this together</em>)</li>
</ol>

<p>Knowing that you want to parallelize something can obviously be factored into design, but is generally easier to do when you satisfy (1) above.</p>

<h3 id="putting-it-all-together">Putting it All Together</h3>

<p>We can now easily write a script to download, parse and bulk insert all 23 Chromosome’s DbSNP data into our local database:</p>

<p><a href="https://github.com/seanharr11/snip_warehouse/blob/master/run.py">Github Link</a></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">snip_warehouse</span> <span class="kn">import</span> <span class="n">SnipLoader</span>
<span class="kn">from</span> <span class="nn">snip_warehouse.schema</span> <span class="kn">import</span> <span class="n">init_db</span>


<span class="nb">input</span><span class="p">(</span><span class="s">"Are you sure you want to re-init DB?"</span>
      <span class="s">"This takes 2-3 hrs per chromosome"</span><span class="p">)</span>
<span class="n">init_db</span><span class="p">(</span><span class="n">DB_NAME</span><span class="p">)</span>
<span class="n">snip_loader</span> <span class="o">=</span> <span class="n">SnipLoader</span><span class="p">(</span><span class="n">DB_NAME</span><span class="p">)</span>
<span class="n">chr_suffixes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">23</span><span class="p">)]</span>
<span class="n">chr_suffixes</span> <span class="o">+=</span> <span class="p">[</span><span class="s">"X"</span><span class="p">,</span> <span class="s">"Y"</span><span class="p">,</span> <span class="s">"MT"</span><span class="p">]</span>
<span class="k">for</span> <span class="n">chr_suffix</span> <span class="ow">in</span> <span class="n">chr_suffixes</span><span class="p">:</span>
    <span class="n">snip_loader</span><span class="o">.</span><span class="n">download_dbsnp_file</span><span class="p">(</span>
        <span class="n">f</span><span class="s">"refsnp-chr{chr_suffix}.json.gz"</span><span class="p">,</span>
        <span class="n">chr_suffix</span><span class="p">)</span>
    <span class="n">snip_loader</span><span class="o">.</span><span class="n">load_ref_snps</span><span class="p">(</span>
        <span class="n">f</span><span class="s">"refsnp-chr{chr_suffix}.json.gz"</span><span class="p">,</span>
        <span class="n">chr_suffix</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="n">f</span><span class="s">"rm refsnp-chr{chr_suffix}.json.gz"</span><span class="p">)</span>
</code></pre></div></div>

<p>More good news, on my 2016, 8-core Macbook Pro (w/ SSD), the Wall Time of warehousing the data of all 23 Chromosomes is <strong>9 hours and 21 minutes.</strong> This satisfies the “overnight goal” - you can kick the above script off before bed, wake up, eat breakfast, and it should be done!</p>

<h3 id="whats-next">What’s Next?</h3>

<blockquote>
  <p>You can find the full <a href="https://github.com/seanharr11/snip_warehouse">source code repo on github here</a></p>
</blockquote>

<p>By open-sourcing this project, it is my hope that folks can take snippets from the walkthrough to build their own hand-curated, DbSNP-related database. Whether you are a Bioinformatician, a hobbying dev, or a PhD without much time or money, don’t recreate the wheel. Take bits and pieces and build something better.</p>

<p>I’ve already built one practical application of this database: The Snip API. This API allows a user to turn his/her <code class="highlighter-rouge">23&amp;Me</code> <a href="https://you.23andme.com/tools/data/download/">Raw SNP Export</a> into insights. It helped me discover that <a href="https://www.youtube.com/watch?v=bTAFl8P2DkE&amp;feature=youtu.be&amp;t=3115">the instigator of my father’s Gallstones and Gallbladder removal was likely genetic</a>.</p>

<blockquote>
  <p>You can find the Snip API client <a href="https://github.com/seanharr11/snip-api-client">on github here</a>.</p>
</blockquote>

<p>I encourage everyone to use the API, and explore the JSON output: you will likely find something of interest. Further, I would encourage folks to:</p>
<ol>
  <li>Build more APIs like it</li>
  <li>Build a GUI for Snip</li>
  <li>Find bugs/issues with Snip</li>
  <li>Integrate this data with other datasets</li>
  <li>Share all of this code/information with as many people as you can!</li>
</ol>

<p>It’s an exciting time for the intersection of Biology and Software Engineering. My hope is that we can all ride the wave.</p>


        </section>

        <footer class="post-footer">

            <!-- Everything inside the #author tags pulls data from the author -->
            <!-- #author-->
            

            <!-- Add Disqus Comments -->
            

        </footer>

    </article>

</main>

<aside class="read-next">

    <!-- [[! next_post ]] -->
    
    <!-- [[! /next_post ]] -->
    <!-- [[! prev_post ]] -->
    
        <a class="read-next-story prev " style="background-image: url(/assets/images/southie_sunset_red.jpg)" href="/bioinformatics/warehousing-DbSNP-Part-II-parsing-RefSNP-JSON">
            <section class="post">
                <h2>Warehousing DbSNP, Part II: Streaming and Parsing SNP Data</h2>
                <p>Intro Part II of our adventure to warehouse a subset of DBbSNP’s JSON data picks...</p>
            </section>
        </a>
    
    <!-- [[! /prev_post ]] -->
</aside>

<!-- /post -->


        <!-- The tiny footer at the very bottom -->
        <footer class="site-footer clearfix">
          <section class="copyright"><a href="/">The Laziest Programmer</a> &copy; 2018</section>
          <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> using <a href="https://github.com/jekyller/jasper">Jasper</a></section>
        </footer>
    </div>
    <!-- highlight.js -->
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- jQuery needs to come before `` so that jQuery can be used in code injection -->
    <script type="text/javascript" src="//code.jquery.com/jquery-1.12.0.min.js"></script>
    <!-- Ghost outputs important scripts and data with this tag -->
    <!--  -->
    <!-- Add Google Analytics  -->
        <!-- Google Analytics Tracking code -->
     <script>
	    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	    ga('create', 'UA-80966627-1', 'auto');
	    ga('send', 'pageview');

     </script>
    <!-- Fitvids makes video embeds responsive and awesome -->
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <!-- The main JavaScript file for Casper -->
    <script type="text/javascript" src="/assets/js/index.js"></script>

</body>
</html>
