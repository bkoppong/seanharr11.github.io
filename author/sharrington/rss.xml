<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>thelaziestprogrammer.com</title>
   
   <link>http://thelaziestprogrammer.com</link>
   <description>Because someone else has already solved your problem.</description>
   <language>en-uk</language>
   <managingEditor> Sean Harrington</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Solving Logistic Regression with Newton's Method</title>
	  <link>/sharrington/math-of-machine-learning/solving-logreg-newtons-method</link>
	  <author>Sean Harrington</author>
	  <pubDate>2017-07-06T11:32:00-04:00</pubDate>
	  <guid>/sharrington/math-of-machine-learning/solving-logreg-newtons-method</guid>
	  <description><![CDATA[
	     <p><br />
In this post we introduce <strong>Newton’s Method</strong>, and how it can be used to solve <strong>Logistic Regression</strong>. Logistic Regression introduces the concept of the <strong>Log-Likelihood</strong> of the Bernoulli distribution, and covers a neat transformation called the <strong>sigmoid function</strong>.</p>

<p>We also introduce <strong>The Hessian</strong>, a square matrix of second-order partial derivatives, and how it is used in conjunction with <strong>The Gradient</strong> to implement Newton’s Method.</p>

<p>Similiar to the <a href="http://thelaziestprogrammer.com/sharrington/math-of-machine-learning/the-gradient-a-visual-descent">initial post covering Linear Regression and The Gradient</a>, we will explore Newton’s Method  visually, mathematically, and programatically with Python to understand how our math concepts translate to implementing a practical solution to the problem of binary classification: Logistic Regression.</p>

<p><strong>Suggested prior knowledge:</strong></p>

<ol>
  <li>Derivatives and the Chain Rule (<em>Calculus</em>)</li>
  <li>Partial Derivatives &amp; <a href="http://http://thelaziestprogrammer.com/sharringto
 n/math-of-machine-learning/the-gradient-a-visual-descent">The Gradient</a>(<em>Multivariate Calculus</em>)</li>
  <li>Basic Vector Operations (<em>Linear Algebra</em>)</li>
  <li>Basic Understanding of NumPy</li>
  <li>Basic Understanding of Independent Probability</li>
</ol>

<h3 id="the-data">The Data</h3>

<p>Our dataset is made up of South Boston real estate data, including the value of each home, and a (<em>boolean</em>) column indicating if that home <em>has more than 2 bathrooms</em>.</p>

<p><script type="math/tex">\hat{x} = HomeValue = \left\langle 550000.00, 600000.00, ... 578000.00\right\rangle^{T}</script>
<script type="math/tex">\hat{y} = MoreThan2Bathrooms = \left\langle 1, 0, 0, ... 1\right\rangle^{T}</script></p>

<p><img src="/assets/images/plotly/south_boston_bedroom_logreg_raw.png" alt="S. Boston Homes - Homes with more than 2 Bedrooms" /></p>

<h3 id="the-model">The Model</h3>

<p>We will be learning a <strong>Logistic Regression</strong> model, that will act as a <strong>binary classifier</strong> predicting whether or not a home has more than 2 bathroom, given its value (in dollars).</p>

<p>We still want to solve a linear combination of features &amp; weights, but we need to transform this linear combination by wrapping it in a function that is smooth, and has its range defined as \([0, 1]\) (<em>because we are trying to map our linear combination to a binary output of 0 or 1!</em>)</p>

<p>The logistic function, or <strong>sigmoid function</strong>, accomplishes all of these things:</p>

<script type="math/tex; mode=display">h(x) = 1 / (1 + e^{-z}),\ \ z = \theta_{1}x + \theta_{2}</script>

<p><strong>Note:</strong> <em>We add \(\theta_{2}\) to the exponent as “the intercept” to provide more flexibility; we have 1 dimension of data, <strong>house_value</strong>, but we are solving a 2-dimensional model!</em></p>

<p><img src="/assets/images/sigmoid_function.png" alt="Sigmoid Function" /></p>

<p>Similiar to the way we defined our <strong>sum of squares</strong> objective function for linear regression, we want to use our hypothesis function, \(h(x)\), and formulate our <strong>likelihood function</strong> to maximize and fit our weights. <strong>Here’s where things get mathy:</strong></p>

<h3 id="the-math-defining-a-likelihood-function">The Math: Defining a Likelihood Function</h3>

<p>First we need to define a <a href="https://en.wikipedia.org/wiki/Probability_mass_function">Probability Mass Function</a>:</p>

<script type="math/tex; mode=display">P(y=1|\ x;\theta) = h_{\theta}(x)</script>

<script type="math/tex; mode=display">P(y=0|\ x;\theta) = 1 - h_{\theta}(x)</script>

<p><strong>Note:</strong> <em>The left-hand side of the first statement reads “The probability that y equals 1, given a feature-vector \(x\), and the hypothesis function’s weights \(\theta\).” Our hypothesis function (right-hand-side) calculates this probability.</em></p>

<p>These two statements can be condensed into one:</p>

<script type="math/tex; mode=display">P(y|\ x;\theta) = h_{\theta}(x)^{y}(1-h_{\theta}(x))^{1-y}</script>

<p>The table below shows how incorrect predictions by our hypothesis function (i.e. \(h(x)=.25, y=1\)) are penalized by generating low values. It also helps to understand how we condense the two statements into one.</p>

<table>
  <tbody>
    <tr>
      <td>\(h(x)\)</td>
      <td>\(y=0\)</td>
      <td>\(y=1\)</td>
    </tr>
    <tr>
      <td>.25</td>
      <td><strong>.75</strong></td>
      <td><strong>.25</strong></td>
    </tr>
    <tr>
      <td>.5</td>
      <td><strong>.5</strong></td>
      <td><strong>.5</strong></td>
    </tr>
    <tr>
      <td>.75</td>
      <td><strong>.25</strong></td>
      <td><strong>.75</strong></td>
    </tr>
    <tr>
      <td>.9</td>
      <td><strong>.1</strong></td>
      <td><strong>.9</strong></td>
    </tr>
  </tbody>
</table>

<p>Naturally, we want to maximize the right-hand-side of the above statement, which happens to be our <strong>likelihood function</strong>.</p>

<p>I like to think of the <strong>likelihood function</strong> as “<em>the likelihood that our model will <strong>correctly</strong> predict any given \(y\) value, given its corresponding feature vector \(\hat{x}\)</em>”. It is, however, important to <a href="https://stats.stackexchange.com/questions/2641/what-is-the-difference-between-likelihood-and-probability">distinguish between probability and likelihood.</a>.</p>

<p>Now, we expand our <strong>likelihood</strong> function by applying it to every sample in our training data. We multiply each individual <strong>likelihood</strong> together to get the cumulative likelihood that our model is accurately predicting \(y\) values of our training data:</p>

<script type="math/tex; mode=display">L(\theta) = \prod_{i=1}^{n}p(y_{i}|x_{i};\theta)</script>

<script type="math/tex; mode=display">L(\theta) = \prod_{i=1}^{n}h_{\theta}(x_{i})^{y_{i}}(1-h_{\theta}(x_{i}))^{1-y_{i}}</script>

<p>Seeing that we are multiplying “\(n\)” likelihoods together (<em>all less than 1.0</em>), where \(n\) is the number of training samples, we are going to get a product of magnitude \(10^{-n}\). This is bad news! Eventually, we will <strong>run out of precision</strong>, and Python will turn our very small floats to \(0\).</p>

<p>Our solution is to take the \(log\) of our likelihood function:</p>

<script type="math/tex; mode=display">\ell(\theta) = log\ L(\theta)</script>

<script type="math/tex; mode=display">\ell(\theta) = \sum_{i=1}^{n}y_{i}\log(h_{\theta}(x_{i})) + (1-y_{i})\log(1-h_{\theta}(x_{i}))</script>

<p><strong>Note:</strong> <em>Remember that \(log(xy) = log(x) + log(y)\), and that: \(log(x)^{n} = nlog(x)\)</em>.</p>

<p>This is called the <strong>log-likelihood</strong> of our hypothesis function.</p>

<p>Remember, our hypothesis function penalizes bad predictions by generating small values, so we want to <strong>maximize the log-likelihood.</strong> The curve of our log-likelihood is shown below:</p>

<p><img src="/assets/images/plotly/log_likelihood_normalized.png" alt="Log-likelihood Curve" /></p>

<p><em><strong>Note:</strong> By taking the log of our function to derive the <strong>log-likelihood</strong>, we guarantee (as an added bonus) that our objective function is <strong>strictly concave</strong>, meaning there is 1 global maximum.</em></p>

<h3 id="the-math-newtons-method-with-one-variable">The Math: Newton’s Method with One Variable</h3>

<p>Before we maximize our log-likelihood, let’s introduce <strong>Newton’s Method</strong>.</p>

<p><strong>Newton’s Method</strong> is an iterative equation solver: it is an algorithm to find the roots of a polynomial function. In the simple, one-variable case, Newton’s Method is implemented as follows:</p>

<ol>
  <li><em>Find the tangent line to \(f(x)\) at point \((x_{n}, y_{n})\)</em>
    <ul>
      <li>\(y = f’(x_{n})(x - x_{n}) + f(x_{n})\)</li>
    </ul>
  </li>
  <li><em>Find the x-intercept of the tangent line, \(x_{n+1}\)</em>
    <ul>
      <li>\(0 = f’(x_{n})(x_{n+1} - x_{n}) + f(x_{n})\)</li>
      <li>\(-f(x_{n}) = f’(x_{n})(x_{n+1} - x_{n})\)</li>
      <li>\(x_{n+1} = x_{n} - \frac{f(x_{n})}{f’(x_{n})}\)</li>
    </ul>
  </li>
  <li><em>Find the \(y\) value at the x-intercept.</em>
    <ul>
      <li>\(y_{n+1} = f(x_{n+1})\)</li>
    </ul>
  </li>
  <li><em>If \(y_{n+1} - y_{n} \approx 0\):</em>
    <ul>
      <li><strong>return \(y_{n+1}\)</strong> because we’ve converged!</li>
    </ul>
  </li>
  <li><em>Else update point \((x_{n}, y_{n})\), and iterate</em>
    <ul>
      <li>\(x = x_{n+1}, y = y_{n+1}\), <strong>goto (1)</strong>.</li>
    </ul>
  </li>
</ol>

<p>The following .gif (from Wikipedia) helps to visualize this method:</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/e/e0/NewtonIteration_Ani.gif" alt="Newton's Method .gif" /></p>

<p>If you understand the more-verbose algorithm above, you will see that this boils down to:</p>

<ol>
  <li><strong>Until \(x_{n} - x_{n+1} \approx 0 \):</strong>
    <ul>
      <li>\(x_{n+1} = x_{n} - \frac{f(x_{n})}{f’(x_{n})}\)</li>
    </ul>
  </li>
</ol>

<p>Anyone who passed high school Calculus may be able to understand the above. But how do we generalize to the multivariate, “n-dimensional” case?</p>

<h3 id="the-math-newtons-method-in-n-dimensions">The Math: Newton’s Method in N-dimensions</h3>

<p>Recall that in n-dimensions, we replace single-variable derivatives with a vector of partial derivatives called the <strong>gradient</strong>.</p>

<p><a href="http://thelaziestprogrammer.com/sharrington/math-of-machine-learning/the-gradient-a-visual-descent#the-math-finding-the-gradient">Review the gradient here</a> if this concept is fuzzy to you.</p>

<p>Thus, our update rule, in its multivariate form, becomes our vector of parameters \(\hat{x}\), minus the scalar \(f(\hat{x})\) multiplied by the inverse of the gradient vector:</p>

<script type="math/tex; mode=display">\hat{x}_{n+1} = \hat{x}_{n} - f(\hat{x}_{n})*\nabla f(\hat{x}_{n})^{-1}</script>

<p><strong>Note:</strong> <em>The \(f’(x_{n})\) in \(\frac{f(x_{n})}{f’(x_{n})}\) becomes \(\nabla f(\hat{x}_{n})^{-1}\) because we generalize the “reciprocal of the scalar,  \(f(x_{n})\)” to the multivariate case, replacing it with the “inverse of the gradient, \(\nabla f(\hat{x}_{n})^{-1}\)”.</em></p>

<h3 id="the-math-maximizing-log-likelihood-with-newtons-method">The Math: Maximizing Log-Likelihood with Newton’s Method</h3>

<p>Recall that we want to maximize the log-likelihood, \(\ell(\theta)\) of our hypothesis function, \(h_{\theta}(x)\)</p>

<p>To maximize our function, we want to find the partial derivatives of \(\ell(\theta)\), and set them equal to 0, and solve for \(\theta_{1}\) and \(\theta_{2}\) to find the <a href="https://en.wikipedia.org/wiki/Critical_point_(mathematics)#Application_to_optimization">critical point</a> of the partials. This critical point will be the <strong>max</strong> of our log-likelihood.</p>

<p><strong>Note:</strong> <em>Since the log-likelihood is strictly concave, we have one <strong>global max</strong>. This means that we only have 1 <strong>critical point</strong>, so our solution hashed out above is the only solution!</em></p>

<p>This should sound familiar. We are trying to find values for \(\theta_{1}\) and \(\theta_{2}\) that make the partial derivatives 0. We are finding the <em>“roots”</em> of the vector of partials (<em>the gradient</em>). We can use Newton’s Method to this! Recall the update step in Newton’s Method:</p>

<script type="math/tex; mode=display">\hat{x}_{n+1} = \hat{x}_{n} - f(\hat{x}_{n})\frac{1}{\nabla f(\hat{x}_{n})}</script>

<p>We can substitute \(f(\hat{x}_{n})\) with the gradient, \(\nabla \ell(\theta)\), leaving us with:</p>

<script type="math/tex; mode=display">\hat{x}_{n+1} = \hat{x}_{n} - \nabla \ell(\theta)\frac{1}{?}</script>

<p>What about the \(?\) term above? Intuition tells us that we need to take the derivative of the gradient vector, just like we previously took the derivative of \(f(\hat{x}_{n})\).</p>

<p>Enter <strong>The Hessian.</strong></p>

<h3 id="the-math-the-hessian">The Math: The Hessian</h3>

<p>Given our pre-requisite knowledge of <strong>Multivariate Calculus</strong>, we should know that to find the “<em>second-order</em>” partial derivatives of a function, we take the partial derivative of each first-order partial, with respect to each parameter. If we have \(n\) parameters, then we have \(n^{2}\) second-order partial derivatives.</p>

<p>Consequently, The Hessian is a square matrix of second-order partial derivatives of order \(n\ x\ n\).</p>

<p>In our case of 2 parameters, \((\theta_{1}, \theta_{2})\), our Hessian looks as follows:</p>

<script type="math/tex; mode=display">% <![CDATA[
H_{\ell(\hat{\theta})} = \begin{bmatrix}\begin{split}
\frac{\partial^{2}{\ell}}{\partial{\theta_{1}^{2}}} &
\frac{\partial^{2}{\ell}}{\partial{\theta_{1}}\partial{\theta_{2}}} \\
\frac{\partial^{2}{\ell}}{\partial{\theta_{2}}\partial{\theta_{1}}} &
\frac{\partial^{2}{\ell}}{\partial{\theta_{2}^{2}}} \\
\end{split}\end{bmatrix} %]]></script>

<h3 id="the-math-putting-it-all-together">The Math: Putting it all Together</h3>

<p>By substituting <strong>The Hessian</strong> into the <strong>Newton’s Method</strong> update step, we are left with:</p>

<script type="math/tex; mode=display">\theta_{n+1} = \theta_{n} + H_{\ell(\hat{\theta})}^{-1}\nabla \ell(\theta)</script>

<p><strong>Note:</strong> <em>We take the <strong>inverse</strong> of The Hessian, rather than taking its reciprocal because it is a matrix</em></p>

<p>For brevity’s sake, this post leaves out the actual derivation of the gradient and the hessian. Resources to understand the following derivations can be found at:</p>

<ol>
  <li><a href="http://cs229.stanford.edu/notes/cs229-notes1.pdf">Derivation of the Gradient of our Log-Likelihood</a>, Andrew Ng’s lecture notes, pages 17-18.</li>
  <li>The derivation of the hessian is pretty straight forward, given Andrew Ng’s notes on the derivative of the <strong>sigmoid function</strong>, \(g’(z)\), once you’ve calculated the gradient.</li>
</ol>

<p>The <strong>gradient</strong> of \(\ell(\theta)\) is:</p>

<script type="math/tex; mode=display">\nabla \ell = \left\langle\matrix{
\sum_{i=1}^{n}(y_{i} - h_{\theta}(x_{i}))x_{i}\cr
\sum_{i=1}^{n}(y_{i} - h_{\theta}(x_{i}))
}\right\rangle</script>

<p>While the <strong>hessian</strong> of \(\ell(\theta)\) is:</p>

<script type="math/tex; mode=display">% <![CDATA[
H_{\ell(\hat{\theta})} = \begin{bmatrix}\begin{split}
\sum_{i=1}^{n}h_{\theta}(x_{i})(1-h_{\theta}(x_{i}))\theta_{1}\theta_{1},\ &
\sum_{i=1}^{n}h_{\theta}(x_{i})(1-h_{\theta}(x_{i}))\theta_{1}\\
\sum_{i=1}^{n}h_{\theta}(x_{i})(1-h_{\theta}(x_{i}))\theta_{1},\ &
\sum_{i=1}^{n}h_{\theta}(x_{i})(1-h_{\theta}(x_{i}))
\end{split}\end{bmatrix} %]]></script>

<p>Where \(h_{\theta}(x) = \frac{1}{1 + e^{-z}}\) and \(z = \theta_{1}x + \theta_{2}\).</p>

<h3 id="implementing-newtons-method">Implementing Newton’s Method</h3>

<p>We start off by defining our <strong>hypothesis function</strong>, which is the <strong>sigmoid function</strong>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">):</span>                                                        
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="err">Θ</span><span class="n">_1</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"float_"</span><span class="p">)</span>                                              
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>                                                
</code></pre>
</div>

<p>Then we define \(\ell(\theta)\), our <strong>log-likelihood</strong> function:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">):</span>                                                                
    <span class="n">sigmoid_probs</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">)</span>                                        
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigmoid_probs</span><span class="p">)</span>
                  <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_probs</span><span class="p">))</span>                                     
</code></pre>
</div>

<p>Finally, we implement the <strong>gradient</strong> and the <strong>hessian</strong> of our log-likelihood.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">):</span>                                                         
    <span class="n">sigmoid_probs</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">)</span>                                        
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">sigmoid_probs</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">),</span>                          
                     <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">sigmoid_probs</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span><span class="p">)]])</span>                         

<span class="k">def</span> <span class="nf">hessian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">):</span>                                                          
    <span class="n">sigmoid_probs</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">)</span>                                        
    <span class="n">d1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">sigmoid_probs</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_probs</span><span class="p">))</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>                  
    <span class="n">d2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">sigmoid_probs</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_probs</span><span class="p">))</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">1</span><span class="p">)</span>                  
    <span class="n">d3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">sigmoid_probs</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_probs</span><span class="p">))</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">*</span> <span class="mi">1</span><span class="p">)</span>                  
    <span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">],[</span><span class="n">d2</span><span class="p">,</span> <span class="n">d3</span><span class="p">]])</span>                                           
    <span class="k">return</span> <span class="n">H</span>
</code></pre>
</div>

<p>With all of our math implemented in these 4 functions, we can create the outer <em>while loop</em> and iterate using <strong>Newton’s Method</strong> until we converge on the maximum.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">newtons_method</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>                                                             
    <span class="s">"""
    :param x (np.array(float)): Vector of Boston House Values in dollars
    :param y (np.array(boolean)): Vector of Bools indicting if house has &gt; 2 bedrooms:
    :returns: np.array of logreg's parameters after convergence, [Θ_1, Θ_2]
    """</span>

    <span class="c"># Initialize log_likelihood &amp; parameters                                                                   </span>
    <span class="err">Θ</span><span class="n">_1</span> <span class="o">=</span> <span class="mf">15.1</span>                                                                     
    <span class="err">Θ</span><span class="n">_2</span> <span class="o">=</span> <span class="o">-.</span><span class="mi">4</span> <span class="c"># The intercept term                                                                 </span>
    <span class="err">Δ</span><span class="n">l</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Infinity</span>                                                                
    <span class="n">l</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">)</span>                                                                 
    <span class="c"># Convergence Conditions                                                        </span>
    <span class="err">δ</span> <span class="o">=</span> <span class="o">.</span><span class="mo">0000000001</span>                                                                 
    <span class="n">max_iterations</span> <span class="o">=</span> <span class="mi">15</span>                                                            
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>                                                                           
    <span class="k">while</span> <span class="nb">abs</span><span class="p">(</span><span class="err">Δ</span><span class="n">l</span><span class="p">)</span> <span class="o">&gt;</span> <span class="err">δ</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">max_iterations</span><span class="p">:</span>                                       
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>                                                                      
        <span class="n">g</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">)</span>                                                      
        <span class="n">hess</span> <span class="o">=</span> <span class="n">hessian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">)</span>                                                 
        <span class="n">H_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">hess</span><span class="p">)</span>                                                 
        <span class="c"># @ is syntactic sugar for np.dot(H_inv, g.T)¹</span>
        <span class="err">Δ</span> <span class="o">=</span> <span class="n">H_inv</span> <span class="err">@</span> <span class="n">g</span><span class="o">.</span><span class="n">T</span>                                                             
        <span class="err">ΔΘ</span><span class="n">_1</span> <span class="o">=</span> <span class="err">Δ</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                                                              
        <span class="err">ΔΘ</span><span class="n">_2</span> <span class="o">=</span> <span class="err">Δ</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                                                              
                                                                                    
        <span class="c"># Perform our update step                                                    </span>
        <span class="err">Θ</span><span class="n">_1</span> <span class="o">+=</span> <span class="err">ΔΘ</span><span class="n">_1</span>                                                                 
        <span class="err">Θ</span><span class="n">_2</span> <span class="o">+=</span> <span class="err">ΔΘ</span><span class="n">_2</span>                                                                 
                                                                                    
        <span class="c"># Update the log-likelihood at each iteration                                     </span>
        <span class="n">l_new</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">)</span>                                                      
        <span class="err">Δ</span><span class="n">l</span> <span class="o">=</span> <span class="n">l</span> <span class="o">-</span> <span class="n">l_new</span>                                                           
        <span class="n">l</span> <span class="o">=</span> <span class="n">l_new</span>                                                                
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="err">Θ</span><span class="n">_1</span><span class="p">,</span> <span class="err">Θ</span><span class="n">_2</span><span class="p">])</span>                                       
</code></pre>
</div>

<h3 id="visualizing-newtons-method">Visualizing Newton’s Method</h3>

<p>Let’s see what happens when we plot each iteration of Newton’s Method on our log-likelihood function’s surface:</p>

<p><strong>Note:</strong> <em>The first iteration is <em style="color: red">red</em>, the second iteration is <em style="color: orange">orange</em>….final iteration is <em style="color: purple">purple</em></em></p>

<p><img src="/assets/images/plotly/newtons_method_ll.png" alt="Newton's Method Logistic Regression" /></p>

<p>This graphic lends confirmation that our “purple” point is in fact the max, and that we have converged succesfully!</p>

<p><img src="/assets/images/plotly/newtons_method_max.png" alt="Newton's Method Maximum of LL" /></p>

<h3 id="visualizing-our-solution">Visualizing our Solution</h3>

<p>Normally, to visualize a 1-Dimensional dataset, you’d plot all of the points on a number-line, and place a boundary somewhere along the line. The problem here is that all of the data points get bunched together.</p>

<p>So instead, I’ve “stretched them out” along a y-axis, and labeled the points by color. We’ve also drawn 3 linear boundaries to separate the homes into percentiles – explained by the legend.</p>

<p><img src="/assets/images/plotly/south_boston_bedroom_logreg.png" alt="S. Boston Homes - Probability of Having &gt;2 Bedrooms" /></p>

<h3 id="conclusion">Conclusion</h3>

<p>we have covered a number of new topics, including <strong>The Hessian</strong>, <strong>Log-likelihood</strong> and <strong>The Sigmoid Function</strong>. Combining these methods together, we’ve been able implement <strong>Newton’s Method</strong> to solve <strong>Logistic Regression</strong>.</p>

<p>While these concepts enforce a <strong>very</strong> concrete foundation to implement our solution, we still need to be wary of things that can cause Newton’s Method to diverge. These are out of scope here, but you can read more on divergence here!</p>


	  ]]></description>
	</item>

	<item>
	  <title>Gradient Descent: High Learning Rates & Divergence</title>
	  <link>/sharrington/math-of-machine-learning/gradient-descent-learning-rate-too-high</link>
	  <author>Sean Harrington</author>
	  <pubDate>2017-07-01T03:26:00-04:00</pubDate>
	  <guid>/sharrington/math-of-machine-learning/gradient-descent-learning-rate-too-high</guid>
	  <description><![CDATA[
	     <p><br />
We’ve <a href="/sharrington/math-of-machine-learning/the-gradient-a-visual-descent">explored gradient descent</a>, but we haven’t talked about learning rates, and how these hyperparameters are the key differentiators between convergence, and divergence.</p>

<p>More specifically, let’s <strong>visually</strong> explore what happens when we set our learning rate to be too high, and talk about strategies to avoid divergence.</p>

<h3 id="the-code">The Code</h3>

<p>As a refresher, in our example we are trying to minimize the Mean Squared Error (MSE) with gradient descent, by choosing ideal values for (\(a, b\)). Details can be found in the <a href="/sharrington/math-of-machine-learning/the-gradient-a-visual-descent">previous post on the gradient</a></p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="c"># I've experimented w/ Python3.6 unicode symbols in this snippet</span>
<span class="k">def</span> <span class="nf">gradient_descent_mse</span><span class="p">(</span><span class="n">x_vec</span><span class="p">,</span> <span class="n">y_vec</span><span class="p">):</span>    
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_vec</span><span class="p">)</span>   
    <span class="c"># Define Partials &amp; Objective Function (MSE)</span>
    <span class="k">def</span> <span class="nf">J</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>    
       <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(((</span><span class="n">a</span> <span class="o">*</span> <span class="n">x_vec</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_vec</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">dJ_db</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>    
       <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">a</span> <span class="o">*</span> <span class="n">x_vec</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_vec</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
    <span class="k">def</span> <span class="nf">dJ_da</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span> 
       <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">x_vec</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">*</span> <span class="n">x_vec</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_vec</span><span class="p">))</span> <span class="o">/</span> <span class="n">n</span>    
    <span class="c"># Initialize our weights</span>
    <span class="n">a</span> <span class="o">=</span> <span class="mi">250</span>    
    <span class="n">b</span> <span class="o">=</span> <span class="mi">250000</span>                                                                   
    <span class="err">Δ</span><span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Infinity</span>    
    <span class="n">j</span> <span class="o">=</span> <span class="n">J</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="c"># Convergence Conditions</span>
    <span class="err">δ</span> <span class="o">=</span> <span class="mi">1</span>    
    <span class="n">max_iterations</span> <span class="o">=</span> <span class="mi">150</span>
    <span class="c"># Learning Rates ()</span>
    <span class="err">ŋ</span><span class="n">_b</span> <span class="o">=</span> <span class="o">.</span><span class="mi">15</span>
    <span class="err">ŋ</span><span class="n">_a</span> <span class="o">=</span> <span class="o">.</span><span class="mo">00000005</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="nb">abs</span><span class="p">(</span><span class="err">Δ</span><span class="n">j</span><span class="p">)</span> <span class="o">&gt;</span> <span class="err">δ</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">max_iterations</span><span class="p">:</span>                                       
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>                  
        <span class="c"># Find the gradient at the point (a, b)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="p">[</span><span class="n">dJ_da</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">dJ_db</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)]</span>
        <span class="c"># Multiply each partial deriv by its learning rate </span>
        <span class="err">Δ</span><span class="n">a</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="o">-</span><span class="err">ŋ</span><span class="n">_a</span>    
        <span class="err">Δ</span><span class="n">b</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="o">-</span><span class="err">ŋ</span><span class="n">_b</span>    
        <span class="c"># Update our weights                              </span>
        <span class="n">a</span> <span class="o">+=</span> <span class="err">Δ</span><span class="n">a</span>                                                            
        <span class="n">b</span> <span class="o">+=</span> <span class="err">Δ</span><span class="n">b</span>    
        <span class="c"># Update the error at each iteration    </span>
        <span class="n">j_new</span> <span class="o">=</span> <span class="n">J</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>    
        <span class="err">Δ</span><span class="n">j</span> <span class="o">=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">j_new</span>    
        <span class="n">j</span> <span class="o">=</span> <span class="n">j_new</span> 
    <span class="k">print</span><span class="p">(</span><span class="s">"y = {0}x + {1}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">b</span><span class="p">)))</span>
</code></pre>
</div>

<h3 id="plotting-our-gradient-descent">Plotting our Gradient Descent</h3>

<p>When we plot the iterations of our gradient descent algorithm with the above learning rates, we see that we are guided in the right direction by gradient descent:</p>

<p><img src="/assets/images/plotly/gd_learning_rates/gd_lr_good.png" alt="Gradient Descent: Good Learning Rates" /></p>

<p>Let’s now see what happens if we bump up the learning rate of our variable \(a\) by a factor of <strong>~10</strong>…</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    <span class="err">ŋ</span><span class="n">_b</span> <span class="o">=</span> <span class="o">.</span><span class="mi">15</span>
    <span class="c">#ŋ_a =.00000005</span>
    <span class="err">ŋ</span><span class="n">_a</span> <span class="o">=</span> <span class="o">.</span><span class="mo">000000575</span>
</code></pre>
</div>

<p><img src="/assets/images/plotly/gd_learning_rates/gd_lr_bad.png" alt="Gradient Descent: Learning Rates that are too high" /></p>

<p>Huh? What happened here? Our z-axis has a range of \([0…8e+42]\); many magnitudes greater than our “good” graph, causing our “objective function surface” to disappear into oblivion. Additionally, our error is increasing with every iteration!</p>

<p>Let’s cut the number of iterations down from 150, to 7 to see what is actually going on:</p>

<p><img src="/assets/images/plotly/gd_learning_rates/gd_lr_bad_7_iterations.png" alt="Gradient Descent: Learning Rates that are too high, zoomed" /></p>

<p>Ok. So that makes a bit more sense. <strong>Here’s what’s happening</strong>:</p>

<ol>
  <li>We start at the white point in the “valley”, and calculate the gradient at that point.</li>
  <li>We multiply our learning rates by our gradient and move along this vector to our new point (the slightly greenish point to the left of the white point)
    <ul>
      <li><em>Because our learning rate was so high, combined with the magnitude of the gradient, we “jumped over” our local minimum.</em></li>
    </ul>
  </li>
  <li>We calculate our gradient at point 2, and make our next move, again, jumping over our local minimum
    <ul>
      <li><em>Our gradient at point 2 is even greater than the gradient at point 1!</em></li>
      <li><em>Our next step will again, jump over our valley, and we will rinse and repeat for eternity…</em></li>
    </ul>
  </li>
  <li>Due to the convex, valley-like curve of our objective function, as we continue to jump from side to side, the gradient at each jump grows higher. Our error increases quadratically with each “jump”, and our algorithm diverges to infinite error.</li>
</ol>

<p><em><strong>Note:</strong> Just the “valley-jumping” alone is a problem that needs fixing - it can lead to slow convergence, and worse, divergence. I’ve chosen this example with runaway quadratic ascension because it was an easy way to choose a diverging gradient descent.</em></p>

<h3 id="remedies">Remedies</h3>

<p>Of course, we can <strong>manually tweak</strong> our learning rates for each weight until we find that our model converges.</p>

<p>Or, naively, to prevent our “runaway gradient ascent”, we could implement a simple check for this case in our loop. If we gain error (rather than losing it), we can divide the deltas (<em>which get added to our weights</em>) by 2, until we see a drop in error. (<em>Line 8 below</em>)</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    <span class="k">while</span> <span class="nb">abs</span><span class="p">(</span><span class="err">Δ</span><span class="n">j</span><span class="p">)</span> <span class="o">&gt;</span> <span class="err">δ</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">max_iterations</span><span class="p">:</span>                                       
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>                  
        <span class="c"># Find the gradient at the point (a, b)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="p">[</span><span class="n">dJ_da</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">dJ_db</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)]</span>
        <span class="c"># Multiply each partial deriv by its learning rate </span>
        <span class="err">Δ</span><span class="n">a</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="o">-</span><span class="err">ŋ</span><span class="n">_a</span>    
        <span class="err">Δ</span><span class="n">b</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="o">-</span><span class="err">ŋ</span><span class="n">_b</span>    
        <span class="k">while</span> <span class="n">J</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="err">Δ</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="err">Δ</span><span class="n">b</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">j</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Error increased, decreasing LRs"</span><span class="p">)</span>
            <span class="err">Δ</span><span class="n">a</span> <span class="o">/=</span> <span class="mi">2</span>
            <span class="err">Δ</span><span class="n">b</span> <span class="o">/=</span> <span class="mi">2</span>
        <span class="c"># Update our weights                              </span>
        <span class="n">a</span> <span class="o">+=</span> <span class="err">Δ</span><span class="n">a</span>                                                            
        <span class="n">b</span> <span class="o">+=</span> <span class="err">Δ</span><span class="n">b</span>    
        <span class="c"># Update the error at each iteration    </span>
        <span class="n">j_new</span> <span class="o">=</span> <span class="n">J</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>    
        <span class="err">Δ</span><span class="n">j</span> <span class="o">=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">j_new</span>    
        <span class="n">j</span> <span class="o">=</span> <span class="n">j_new</span>
</code></pre>
</div>

<p>In our specific case, the above works. Our plotted gradient descent looks as follows:</p>

<p><img src="/assets/images/plotly/gd_learning_rates/gd_lr_power_of_2_backoff.png" alt="Gradient Descent: Power of 2 Step Size Backoff" /></p>

<p>In a more general, higher-dimensional example, some techniques to set learning rates such that you avoid the problems of divergence and “valley-jumping” include:</p>

<ol>
  <li><strong>Momentum</strong> - Add an additional term to the weight update formula, which, in our “ball down the hill” analogy, will help to get our ball rolling by compounding past gradients.</li>
  <li><strong>Backtracking Line Search</strong> - Dynamically make <em>smart</em> choices for the learning rate at each iteration by taking a step <em>far enough</em> in the direction of the gradient, but not so far that we increase our error.</li>
  <li><strong>Stochastic Gradient Descent</strong> - A faster (and often better) optimization algorithm that calculates gradients from single (\(x, y\)) samples, rather than the entire batch. The additional <em>noise</em> can be of help here, as you may get an errant data point that kicks off your path down the valley, rather than our divergent model above.</li>
  <li><strong>Normalization of Data</strong> - Normalizing data creates a less <a href="http://www.ou.edu/class/che-design/che5480-13/Optimization%20of%20Chemical%20Processes-Chapter%204.pdf">elliptical contour</a>, and will influence our objective function to have a more <strong>concentric circle</strong> countour (<em>think a circular mountain base instead of an elliptical base!</em>).</li>
</ol>

<p>We will not cover these here for the brevity’s sake, but feel free to explore on your own.</p>

	  ]]></description>
	</item>

	<item>
	  <title>The Gradient: A Visual Descent</title>
	  <link>/sharrington/math-of-machine-learning/the-gradient-a-visual-descent</link>
	  <author>Sean Harrington</author>
	  <pubDate>2017-06-16T09:32:00-04:00</pubDate>
	  <guid>/sharrington/math-of-machine-learning/the-gradient-a-visual-descent</guid>
	  <description><![CDATA[
	     <p><br />
In this post I aim to visually, mathematically and programatically explain <strong>the gradient</strong>, and how its understanding is crucial for <strong>gradient descent</strong>. For those unfamiliar, gradient descent is used in various ML models spanning from logistic regression, to neural nets. Ultimately, gradient descent, and transitively <strong>the gradient</strong>, are the blueprints that guide these models to converge on ideal weights.</p>

<p>In short, The gradient is an n-dimensional generalization of the derivative, which can be applied in any direction.</p>

<p>For a complete understanding of the content in this post, I would suggest a firm understanding of the following topics:</p>

<ol>
  <li>Derivatives and the Chain Rule (<em>Calculus</em>)</li>
  <li>Partial Derivatives (<em>Multivariate Calculus</em>)</li>
  <li>Basic Vector Operations (<em>Linear Algebra</em>)</li>
  <li>Objective Functions (<em>Also called Loss Function</em>)</li>
  <li>Basic Understanding of NumPy</li>
</ol>

<h3 id="the-data">The Data</h3>

<p>Our dataset is made up of South Boston home sales, and consists of 2 very simple column vectors:</p>

<p><script type="math/tex">\hat{y} = HomeValue = \left\langle 550000.00, 600000.00, ... 578000.00\right\rangle^{T}</script>
<script type="math/tex">\hat{x} = LivingArea = \left\langle 990, 1046, ... 1010\right\rangle^{T}</script></p>

<h3 id="the-model">The Model</h3>

<p>We will be learning a simple Linear Regression model, that predicts a home in South Boston’s value (sale price) based solely on the Living Area of the property. We want to fit a line to our data, defined by:</p>

<script type="math/tex; mode=display">\hat{y} = a\hat{x} + b</script>

<p>Our line should overlay our data as follows:
<img src="/assets/images/plotly/south_boston_home_sales_lr.png" alt="S. Boston - LinReg" />
Thus, our main objective is to minimize the distance between each point and our line. We will use <strong>Mean Squared Error</strong> as our objective function, which is a fancy way of saying: <em>“For each point (x, y) in our dataset, take the squared distance between the y-value, and the predicted y-value, and add them all up. Then divide by the number of examples, n.”</em></p>

<p>In mathematical fancy notation, the Mean Squared Error looks as follows:</p>

<script type="math/tex; mode=display">J(a, b) = \frac{1}{n}\sum_{i=1}^{n}(y_{i,actual} - y_{i,predicted})^{2}</script>

<p>Using our above objective function, (\(y_{i,predicted} = ax_{i} + b,\)) we get:</p>

<script type="math/tex; mode=display">J(a, b) = \frac{1}{n}\sum_{i=1}^{n}(y_{i} - (ax_{i} + b))^{2}</script>

<p>Our goal is to minimize this function, and we do so with the gradient.</p>

<p>Let’s begin with the most naive solution to find our minimum: take every combination of \(a\) and \(b\), then find the combination that yields the lowest error \(J(a, b\)).</p>

<p>The problem: What if (rather than \(a\) and \(b\) ) we have 10,000 variables to solve for? We would find ourselves in a permutational nightmare that no computer could handle!</p>

<p>We need a way to gracefully and quickly find our minimum: and we use the gradient to do so.</p>

<h3 id="the-math-finding-the-gradient">The Math: Finding the Gradient</h3>

<p>The gradient is a vector of the partial derivatives of a function. It is the n-dimensional generalization of the derivative, defining the rate of change with respect to all “n” variables. It is usually written as follows:</p>

<script type="math/tex; mode=display">\nabla J(\hat{x}) = \left\langle \frac{\partial{J}}{\partial{x_{0}}}, \frac{\partial{J}}{\partial{x_{1}}}, ... \frac{\partial{J}}{\partial{x_{n}}}\right\rangle^{T}</script>

<p>In our case, we need to find both partial derivatives of \(J(a, b)\) - we use the Chain Rule to do so:</p>

<script type="math/tex; mode=display">\frac{\partial{J}}{\partial{a}} = \frac{1}{n}\sum_{i=1}^{n}x_{i} * 2(y_i - (ax_i + b))</script>

<script type="math/tex; mode=display">\frac{\partial{J}}{\partial{b}} = \frac{1}{n}\sum_{i=1}^{n}2(y_i - (ax_i + b))</script>

<p>Don’t be intimidated by the summation notion when calculating the partials! We are just differentiating the function to the right of the symbol!</p>

<p>Rearranging terms, and distributing terms we get our gradient:</p>

<script type="math/tex; mode=display">\nabla J(a, b) = \left\langle\matrix{
\frac{2}{n}\sum_{i=1}^{n}x_{i}y_{i} - (ax_i^{2} + bx_{i})\cr
\frac{2}{n}\sum_{i=1}^{n}y_{i} - (ax_i + b)
}\right\rangle</script>

<h3 id="the-math-visualizing-the-gradients-significance">The Math: Visualizing the Gradient’s Significance</h3>

<p>If we are standing on the mountain-like curve of our objective function, at point \((a, b)\), we want to find the direction with the greatest rate of negative change.</p>

<p>In other words, we want to find the steepest path down the mountain, because the lower our error (height of our curve), the more accurate our model! Below is the surface of our objective function \(J(a, b)\), and our starting point \((a=340, b=380000)\):</p>

<p><img src="/assets/images/plotly/gd_starting_point.png" alt="Gradient Descent: Starting Point" /></p>

<p>Which direction do we step? It turns out that the direction of the gradient vector, at a given point, will naturally point in the steepest direction!</p>

<p>The gradient will be our guide down the mountain!</p>

<h3 id="the-math-proving-the-gradients-significance">The Math: Proving the Gradient’s Significance</h3>

<p>Here’s where things get a bit “mathy”. Let’s prove why the direction of the gradient vector points in the direction of greatest change.</p>

<p>The rate-of-change of \(J(a, b)\), in a certain direction, \(\vec v\), with respect to distance traveled (\(ds\)), is defined as the gradient dotted with a vector indicating the direction to travel (\(\vec v)\), or:</p>

<script type="math/tex; mode=display">\frac{dJ}{ds} = \nabla (J(a, b))\cdot\vec v</script>

<p><em>All we are saying is that given an arbitrary direction, \(\vec v\), down our mountain, if we travel that direction in \(ds\) units, our error, \(J\), changes at a rate described by the above formula, which depends on the gradient.</em></p>

<p>Using the definition of the dot-product (\(x \cdot y = ||x||\ ||y||\ cos(\theta_{x,y})\)), we can re-write this as the product of each vector’s magnitude, times the cosine of the angle between them:</p>

<script type="math/tex; mode=display">\frac{dJ}{ds} = ||\nabla (J(a, b))||\ ||\vec v||\ cos(\theta)</script>

<p>To maximize the rate of change, we would want to maximize \(cos(\theta)\) by setting  \(\theta = 0\), to get \(1\), the highest possible value of the \(cos()\) function.</p>

<p>If the angle between these two vectors is \(0\), then the two vectors are parallel, therefore:</p>

<script type="math/tex; mode=display">dir(\vec v) = dir(\nabla J)</script>

<p><strong>Our steepest step is in the direction of the gradient!</strong> So we want to travel in the <strong>opposite direction</strong> of the gradient, by multiplying it by \(-1\). If you take anything away from this post, remember this!</p>

<p>Given this fact, at each “step” along our descent, we:</p>

<ol>
  <li>Calculate our gradient at the point \( (a, b) \).
    <ul>
      <li>
        <p style="background-color: #ffff99">We want the negative gradient, so we travel downhill and not uphill!</p>
      </li>
    </ul>
  </li>
  <li>Multiply the gradient by a scalar, (also called a <strong>learning rate</strong>, denoted by \(\eta\))
    <ul>
      <li>The learning rate is what we call a <strong>hyperparameter</strong>, and can be tweaked to ensure convergence. <a href="/sharrington/math-of-machine-learning/gradient-descent-learning-rate-too-high">Set too high or low, the model might converge!</a></li>
    </ul>
  </li>
  <li>Update our weights using our multiplied gradient:
<script type="math/tex">\left\langle a, b \right\rangle += \eta \nabla J</script></li>
  <li>Terminate if we have converged!</li>
</ol>

<h3 id="the-math-implementing-gradient-descent">The Math: Implementing Gradient Descent</h3>

<p>The equivalent code, implemented using Python and NumPy looks as follows:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="c"># I've experimented w/ Python3.6 unicode symbols in this snippet</span>
<span class="k">def</span> <span class="nf">gradient_descent_mse</span><span class="p">(</span><span class="n">x_vec</span><span class="p">,</span> <span class="n">y_vec</span><span class="p">):</span>                                                 
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_vec</span><span class="p">)</span>                                                                      
    <span class="c"># Define Partials &amp; Objective Function (MSE)</span>
    <span class="k">def</span> <span class="nf">J</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>                                                                    
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(((</span><span class="n">a</span> <span class="o">*</span> <span class="n">x_vec</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_vec</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>                                   
    <span class="k">def</span> <span class="nf">dJ_db</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>                                                                
       <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">a</span> <span class="o">*</span> <span class="n">x_vec</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_vec</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>                                           
    <span class="k">def</span> <span class="nf">dJ_da</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>                                                                
       <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">x_vec</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">*</span> <span class="n">x_vec</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_vec</span><span class="p">))</span> <span class="o">/</span> <span class="n">n</span>                                     
    <span class="c"># Initialize our weights                                                        </span>
    <span class="n">a</span> <span class="o">=</span> <span class="mi">350</span>                                                                       
    <span class="n">b</span> <span class="o">=</span> <span class="mi">380000</span>                                                                      
    <span class="err">Δ</span><span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Infinity</span>                                                                
    <span class="n">j</span> <span class="o">=</span> <span class="n">J</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>                                                                     
    <span class="c"># Convergence Conditions                                                        </span>
    <span class="err">δ</span> <span class="o">=</span> <span class="mi">1</span>                                                                           
    <span class="n">max_iterations</span> <span class="o">=</span> <span class="mi">150</span>                                                             
    <span class="c"># Learning Rates (separate rate for each partial)</span>
    <span class="err">ŋ</span><span class="n">_b</span> <span class="o">=</span> <span class="o">.</span><span class="mi">15</span>                                                                       
    <span class="err">ŋ</span><span class="n">_a</span> <span class="o">=</span> <span class="o">.</span><span class="mo">00000005</span>                                                                 
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>                                                                           
    <span class="k">while</span> <span class="nb">abs</span><span class="p">(</span><span class="err">Δ</span><span class="n">j</span><span class="p">)</span> <span class="o">&gt;</span> <span class="err">δ</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">max_iterations</span><span class="p">:</span>                                       
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>                                                                      
        <span class="c"># Find the gradient at the point (a, b)                                     </span>
        <span class="n">grad</span> <span class="o">=</span> <span class="p">[</span><span class="n">dJ_da</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">dJ_db</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)]</span>                                                     
        <span class="c"># Multiply each partial deriv by its learning rate                          </span>
        <span class="err">Δ</span><span class="n">a</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="o">-</span><span class="err">ŋ</span><span class="n">_a</span>                                                         
        <span class="err">Δ</span><span class="n">b</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="o">-</span><span class="err">ŋ</span><span class="n">_b</span>                                                         
        <span class="c"># Update our weights                                                        </span>
        <span class="n">a</span> <span class="o">+=</span> <span class="err">Δ</span><span class="n">a</span>                                                                     
        <span class="n">b</span> <span class="o">+=</span> <span class="err">Δ</span><span class="n">b</span>                                                                     
        <span class="c"># Update the error at each iteration                                        </span>
        <span class="n">j_new</span> <span class="o">=</span> <span class="n">J</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>                                                             
        <span class="err">Δ</span><span class="n">j</span> <span class="o">=</span> <span class="n">j</span> <span class="o">-</span> <span class="n">j_new</span>                                                              
        <span class="n">j</span> <span class="o">=</span> <span class="n">j_new</span> 
    <span class="k">print</span><span class="p">(</span><span class="s">"y = {0}x + {1}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">b</span><span class="p">)))</span>
</code></pre>
</div>

<p>We stop our descent when we have maxed out on iterations, or when we see (very small) decreases in the error calculated by \(J\).</p>

<p>To visualize our graceful descent, the following surface plots 150 iterations of our Gradient Descent, and shows us converging on \( a \approx 148, b \approx 380000\).</p>

<p><img src="/assets/images/plotly/gd_ending_point.png" alt="Gradient Descent: Finish" /></p>

<p>You can clearly see the “path down the mountain”, and visually grasp how the algorithm actually converges.</p>

<p>Our final “line of best fit” after 150 iterations, superimposed atop our data, and the closed-form solution, looks almost identical to our closed-form solution (<em>if we had iterated 100 more times, the lines would have been superimposed, and indistinguishable!</em>):</p>

<p><img src="/assets/images/plotly/south_boston_home_sales.png" alt="S. Boston - LinReg vs Gradient Descent" /></p>

<h3 id="conclusion">Conclusion</h3>

<p>In our example here, we have mathematically, programatically, and visually proved the effectiveness of <strong>Gradient Descent</strong> in minimizing Objective Functions. Perhaps more importantly, we have shed light on <strong>the gradient</strong>, and why it is such a graceful solution to our error minimization.</p>

<p>There are many flavors of Gradient Descent, other than the (naive) implementation provided above. Stochastic Gradient Descent (SGD) is the most commonly used algorithm for minimizations, and is found everywhere from Logistic Regression Classifiers, to Deep Learning and Neural Nets.</p>

<p>Some of you may point out that the above example is trivial! There is a closed solution to this problem of Least Squares Regression! We’ve used this example for simplicity’s sake to introduce <strong>The Gradient</strong> and <strong>Gradient Descent</strong>. <a href="http://thelaziestprogrammer.com/sharrington/math-of-machine-learning/solving-logreg-newtons-method">This post on solving Logistic Regression iteratively</a>, addresses a more practical problem: there is no closed form solution to Logistic Regression!</p>


	  ]]></description>
	</item>

	<item>
	  <title>Upgrading to Flask-restless v1.0.0</title>
	  <link>/sharrington/web-development/upgrading-to-flask-restless-v1.0.0-part-1</link>
	  <author>Sean Harrington</author>
	  <pubDate>2017-03-25T04:36:00-04:00</pubDate>
	  <guid>/sharrington/web-development/upgrading-to-flask-restless-v1.0.0-part-1</guid>
	  <description><![CDATA[
	     <p><br />
<strong>Flask-restless</strong> is a Flask extension providing generation of REST APIs from SQLAlchemy-defined database models. <a href="https://flask-restless.readthedocs.io/en/latest/">Flask-restless v1.0.0</a> introduces adoption of the <a href="http://www.jsonapi.org">jsonapi.org</a> spec, providing  additional features, consistent and strict HTTP Method contracts, at the expense of inherent breaking changes.</p>

<p>This article walks through the most basic of breaking changes found while upgrading from <strong>Flask-restless v0.17</strong> to <strong>Flask-restless v1.0.0</strong>.</p>

<h3 id="flask-app-and-models">Flask App and Models</h3>

<p>For purposes of this walkthrough, we assume a basic understanding of SQLAlchemy, and Flask. We define our Flask app in the following file:</p>

<div class="row">
<div class="col-md-8 col-md-offset-2 highlighter codetight">
<pre class="highlight">
<code class="python">
from flask import Flask
import flask_restless
import flask_sqlalchemy
import simplejson as json

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:////tmp/flask_restless.db'
db = flask_sqlalchemy.SQLAlchemy(app)


class ProgrammingLanguage(db.Model):
    __tablename__ = "programming_languages"
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String, unique=True)
    latest_release = db.Column(db.String)

db.create_all()
# Create the Flask-Restless API manager.
manager = flask_restless.APIManager(app, flask_sqlalchemy_db=db)
manager.create_api(ProgrammingLanguage, methods=['GET', 'POST', 'PATCH', 'DELETE'])

if __name__ == "__main__":
    # Start the server with 'python \&lt;name_of_this_file.py\&gt;'
    app.run()

</code></pre><br /></div></div>

<h2 id="posting-a-row">POSTing a row</h2>

<p>Throughout the walkthrough, we will compare code samples of requests and responses between Flask-restless v0.17 (left), and v1.0.0 (right).</p>

<p>More specifically, we highlight the <em>updates required to get your code working with v1.0.0</em>.  We start with some basic legacy v0.17 code to POST a <code class="highlighter-rouge">programming_language</code> <a href="http://jsonapi.org/format/#document-resource-objects">Resource Object</a> to our database.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"name"</span><span class="p">:</span> <span class="s">"Python"</span><span class="p">,</span>
    <span class="s">"latest_release"</span><span class="p">:</span> <span class="s">"3.6.0"</span>
<span class="p">}</span>
<span class="n">url</span> <span class="o">=</span> <span class="s">"http://localhost:5000/api/programming_languages"</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Content-Type"</span><span class="p">:</span> <span class="s">"application/json"</span><span class="p">}</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">simplejson</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
</code></pre>
</div>

<h4 id="update-1-content-type-header">Update #1: Content-Type Header</h4>

<p>The response content that we receive varies dramatically between Flask-restless v0.17 (left) and v1.0.0 (right).</p>

<div class="row">
<div class="col-md-4 highlighter codetight">
<pre class="highlight">
<code class="python">
# Flask v0.17 Response
&gt;&gt;&gt; resp.status_code
201
&gt;&gt;&gt; resp.content
{
    "id": 1,
    "name": "Python",
    "latest_release": "3.6.0" 
}</code></pre></div>
  <div class="col-md-8 highlighter codetight">
    <pre class="highlight">
<code class="python">
# Flask v1.0.0 Response
&gt;&gt;&gt; resp.status_code
415
&gt;&gt;&gt; resp.content
{
    "errors": [
        {
            "code": null,
            "detail": "Request must have \"Content-Type: application/vnd.api+json\" header",
            "id": null,
            "links": null,
            "meta": null,
            "source": null,
            "status": 415,
            "title": null
        }
    ],
    "jsonapi": {
        "version": "1.0"
    }
}</code></pre>
  </div>
</div>

<p>Quite clearly, we see that we did not set the <code class="highlighter-rouge">Content-Type</code> header according to the <a href="http://jsonapi.org/format/#content-negotiation-clients">jsonapi.org spec</a>, so we get a <a href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.4.16">415 - Unsupported Media Type</a> status.</p>

<p>Let’s set the header to <strong>application/vnd.api+json</strong> below and continue…</p>

<h4 id="update-2-json-wrapped-with-top-level-data-key">Update #2: JSON wrapped with top-level “data” key</h4>
<div class="row">
<div class="col-md-7 highlighter codetight">
<pre class="highlight">
<code class="python">
data = {
    "name": "Python",
    "latest_release": "3.6.0"
}
url = "http://localhost:5000/api/programming_languages"
headers = {"Content-Type": "application/vnd.api+json"}

resp = requests.post(url, simplejson.dumps(data), headers=headers)

&gt;&gt;&gt; resp.status_code
400
&gt;&gt;&gt; resp.content
{
    "errors": [
        {
            "code": null,
            "detail": "Failed to deserialize object: missing \"data\" element",
            "id": null,
            "links": null,
            "meta": null,
            "source": null,
            "status": 400,
            "title": null
        }
    ],
    "jsonapi": {
        "version": "1.0"
    }
}
</code>
</pre>
</div>
<div class="col-md-5">
    <p>This time we see a <a target="_blank" href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.4.1">400 - Bad Request</a> status, which generally means that our JSON payload could not be understood by the server.  Specifically, the error states:</p>
    <p><em>"Failed to deserialize object: missing \"data\" element"</em></p>
    <p>The JSON API spec expects any POST payload to be delivered with its top-level schema of the form <strong>{"data": {....}},</strong> so let's update our payload as follows and try again.</p>
</div>
</div>

<h4 id="update-3-provide-the-type-of-our-posted-object">Update #3: Provide the “type” of our POSTed object</h4>
<div class="row">
<div class="col-md-7 highlighter codetight">
<pre class="highlight">
<code class="python">
data = {
    "name": "Python",
    "latest_release": "3.6.0"
}
url = "http://localhost:5000/api/programming_languages"
headers = {"Content-Type": "application/vnd.api+json")

resp = requests.post(url, simplejson.dumps({"data": programming_language_obj}), headers=headers)

&gt;&gt;&gt; resp.status_code
400
&gt;&gt;&gt; resp.content
{
    "errors": [
        {
            "code": null,
            "detail": "Failed to deserialize object: missing \"type\" element",
            "id": null,
            "links": null,
            "meta": null,
            "source": null,
            "status": 400,
            "title": null
        }
    ],
    "jsonapi": {
        "version": "1.0"
    }
}
</code>
</pre>
</div>
<div class="col-md-5">
<p>Again, we get a 400 status, with the server telling us:</p>
<p><em>"Failed to deserialize object: missing \"type\" element"</em></p>
<p>The <a target="_blank" href="http://jsonapi.org/format/#crud-creating">JSON API spec requires us to provide the <strong>type</strong> of resource that we are creating</a> with our POST request.</p>
<p>In this case, we are posting to the <strong>programming_languages</strong> table, so let's update our query accordingly...</p>

</div>
</div>

<h4 id="update-4-provide-attributes-of-our-posted-object">Update #4: Provide “attributes” of our POSTed object</h4>

<div class="row">
<div class="col-md-7 highlighter codetight">
<pre class="highlight">
<code class="python">
data = {
    "name": "Python", 
    "latest_release": "3.6.0"
    "type": "programming_languages"
}
url = "http://localhost:5000/api/programming_languages"
headers = {"Content-Type": "application/vnd.api+json"}

resp = requests.post(url, simplejson.dumps({"data": data}), headers=headers)

&gt;&gt;&gt; resp.status_code
201
&gt;&gt;&gt; resp.content
{
    "data": {
        "attributes": {
            "name": null,
            "latest_release" null
        },
        "id": "1",
        "links": {
            "self": "http://localhost:5001/api/programming_languages/1"
        },
        "relationships": {},
        "type": "programming_languages"
    },
    "included": [],
    "jsonapi": {
        "version": "1.0"
    },
    "links": {},
    "meta": {}
}
</code>
</pre>
</div>

<div class="col-md-5">
<p>Ahhh, finally a <code>201 - Created</code> status code...<strong>wait a minute</strong>...if we access <code>resp.content['attributes']['name']</code> we see that it has a value of <code>null</code>.</p>
<p>But we created our object with <code>{"name": "Python"}</code>, what happened?</p>
<p>The JSON API spec ignores our top-level <code>name</code> parameter - it is looking for the <code>attributes</code> top-level key to determine the attribute values (column values) of our new <code>programming_language</code> resource object.</p>
<p>Let's update our JSON payload one more time, and take a look at the full diff between v0.17 and v1.0.0</p>
</div>
</div>

<h4 id="post-request---full-comparison">POST Request - Full Comparison</h4>

<div class="row">

<div class="col-md-6 highlighter codetight">
<pre class="highlight">
<code class="python">
# Flask-restless v0.17 POST request
data = {
    "name": "Python",
    "latest_release": "3.6.0"
}
url = "http://localhost:5000/api/programming_languages"
headers = {"Content-Type": "application/json"}

resp = requests.post(url, simplejson.dumps(data), headers=headers)
# Viewing the response of the request
&gt;&gt;&gt; resp.status_code
201
&gt;&gt;&gt; resp.content
{
    "id": 1,
    "name": "Python",
    "latest_release": "3.6.0"
}</code></pre>
<p> There are several fields in our <code>resp.content</code> payload that we have not yet mentioned.</p>

<p>Most notable, is the <code>relationships</code> field nested within the Resource Object (<code>data</code> object). This walkthrough does not cover relationships, but these can be <a href="http://jsonapi.org/format/#fetching-relationships" target="_blank">read about here.</a></p>

<p>You should expect a follow up post covering these more advanced use cases of Flask-restless.</p>
</div>

<div class="col-md-6 highlighter codetight">
<pre class="highlight">
<code class="python">
# Flask-restles v1.0.0 POST request
data = {
    "type": "programming_languages",
    "attributes": {
        "name": "Python",
        "latest_release": "3.6.0"
    }
}
url = "http://localhost:5000/api/programming_languages"
headers = {"Content-Type": "application/vnd.api+json"})

resp = requests.patch(url, simplejson.dumps({"data": data}),
                      headers=headers)
# Viewing the response
&gt;&gt;&gt; resp.status_code
201
&gt;&gt;&gt; resp.content
{
    "data": {
        "attributes": {
            "name": "Python",
            "latest_release": "3.6.0"
        },
        "id": "1",
        "links": {
            "self": "http://localhost:5001/api/programming_languages/1"
        },
        "relationships": {}
        "type": "programming_languages"
    },
    "included": [],
    "jsonapi": {
        "version": "1.0"
    },
    "links": {},
    "meta": {}
}
</code>
</pre>
</div>
</div>

<hr />

<h2 id="getting-all-rows">GETting all Rows</h2>

<p>Next, we will retrieve the resources that we recently POSTed to the database with a GET request</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"http://localhost:5000/api/programming_languages"</span><span class="p">)</span>
</code></pre>
</div>

<div class="row">
    <div class="col-md-4 codetight">
        <pre class="highlight"><code class="python">
# Flask-restless v0.17
&gt;&gt;&gt; resp.status_code
200
&gt;&gt;&gt; resp.content
{
    "num_results": 1,
    "objects": [
        {
            "id": 1,
            "name": "Python",
            "latest_release": "3.6.0"
        }
    ],
    "page": 1,
    "total_pages": 1
}
           </code>
        </pre>
    <br />
    <h5>Key differences</h5>
    <p>
     <ul>
       <li>Size of the resource collection is now givin in <code>resp.content["meta"]["total"]</code></li>
       <li>Objects in this collection are nested as a list via <code>resp.content['data']</code></li>
       <li>Pagination is handled via <code>resp.content["links"]</code></li>
     </ul>
    </p>
    <em><strong>Note</strong>: getting a specific record is still executed via <code>http://localhost:5000/api/programming_languages/1</code>, where 1 is the id of the record. The return format is equal to that of the POSTed data above</em>
     </div>
    <div class="col-md-8 codetight">
        <pre class="highlight"><code class="python">
# Flask-restless v1.0.0
&gt;&gt;&gt; resp.status_code
201
&gt;&gt;&gt; resp.content
{
    "data": [
        {
            "attributes": {
                "name": "Python",
                "latest_release": "3.6.0"
            },
            "id": "1",
            "links": {
                "self": "http://localhost:5001/api/programming_languages/1"
            },
            "relationships": {},
            "type": "programming_languages"
        }
    ],
    "included": [],
    "jsonapi": {
        "version": "1.0"
    },
    "links": {
        "first": "http://localhost:5001/api/programming_languages?page%5Bsize%5D=10&amp;page%5Bnumber%5D=1",
        "last": "http://localhost:5001/api/programming_languages?page%5Bsize%5D=10&amp;page%5Bnumber%5D=1",
        "next": null,
        "prev": null,
        "self": "/api/programming_languages"
    },
    "meta": {
        "total": 1
    }
}
           </code>
        </pre>
  </div>
</div>

<h2 id="patching-a-row">PATCHing a row</h2>

<p>We’ve succesfully created and fetched resources from our Flask-restless API - now let’s update our perviously inserted record with a PATCH request. Below is how we would carry this out with <strong>Flask-restless v0.17</strong>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># Legacy Flask-restless v0.17 code</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"latest_release"</span><span class="p">:</span> <span class="s">"3.6.1"</span>
<span class="p">}</span>
<span class="n">url</span> <span class="o">=</span> <span class="s">"http://localhost:5000/api/programming_languages/1"</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Content-Type"</span><span class="p">:</span> <span class="s">"application/json"</span><span class="p">}</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">patch</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">simplejson</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
</code></pre>
</div>

<p>…if you read the POST section above, you know that we’ve got some work to do. Let’s apply Updates <a href="#update-1-content-type-header">#1</a>, <a href="update-2-json-wrapped-with-top-level-data-key">#2</a>, <a href="update-3-provide-the-type-of-our-posted-object">#3</a>, and <a href="#update-4-provide-attributes-of-our-posted-object">#4</a> to our PATCH request below to try and get our code working with <strong>Flask-restless v1.0.0</strong>.</p>

<h4 id="update-5-supply-resource-id">Update #5: Supply Resource ID</h4>

<div class="row">
    <div class="col-md-7 codetight">
        <pre class="highlight"><code class="python">
data = {
    "type": "programming_languages",
    "attributes": {
        "latest_release": "3.6.1"
    }
}
url = "http://localhost:5000/api/programming_languages/1"
headers = {"Content-Type": "application/vnd.api+json"})

resp = requests.patch(url, simplejson.dumps({"data": data}), headers=headers)
# Print the response
&gt;&gt;&gt; resp.status_code
400
&gt;&gt;&gt; resp.content
{
    "errors": [
        {
            "code": null,
            "detail": "Missing resource ID",
            "id": null,
            "links": null,
            "meta": null,
            "source": null,
            "status": 400,
            "title": null
        }
    ],
    "jsonapi": {
        "version": "1.0"
    }
}</code>
        </pre>
  </div>
  <div class="col-md-5">
      <p>Although we've included the <code>id</code> of the resource we'd like to update in the URL, rather redundantly, the <a href="http://jsonapi.org/format/#crud-updating" target="_blank">JSON API spec for Updates</a> mandates that the "<em>resource object MUST contain <code>id</code> [and <code>type</code>] members</em>".</p>

      <p>Let's add the <code>id</code> field to our resource object (<em>the 'data' object in JSON payload</em>), and fire away...</p>
  </div>
</div>

<h4 id="update-6-resource-id-must-be-a-string">Update #6: Resource ID must be a String</h4>

<div class="row">
    <div class="col-md-8 codetight">
        <pre class="highlight"><code class="python">
data = {
    "type": "programming_languages",
    "id": 1,
    "attributes": {
        "latest_release": "3.6.1"
    }
}
url = "http://localhost:5000/api/programming_languages/1"
headers = {"Content-Type": "application/vnd.api+json"})

resp = requests.patch(url, simplejson.dumps({"data": data}), headers=headers)
# Print the response
&gt;&gt;&gt; resp.status_code
409
&gt;&gt;&gt; resp.content
{
    "errors": [
        {
            "code": null,
            "detail": "The \"id\" element of the resource object must be a JSON string: 1",
            "id": null,
            "links": null,
            "meta": null,
            "source": null,
            "status": 400,
            "title": null
        }
    ],
    "jsonapi": {
        "version": "1.0"
    }
}</code>
        </pre>
  </div>
  <div class="col-md-4">
      <p>Congratulations! You've captured the very elusive <code>409 - Conflict</code> Status Code!</p>
      <p>The spec for this JSON API status code is <a href="http://jsonapi.org/format/#crud-updating-responses-409" target="_blank">explained here</a>, but our specific issue is that our ID needs to be a string (so we can support string-based IDs).</p>
      <p>Let's change <code>"id": 1</code> to <code>"id": "1"</code> and carry on...</p>
  </div>
</div>

<h4 id="patch-request---final-comparison">PATCH Request - Final Comparison</h4>

<div class="row">
    <div class="col-md-6 codetight">
        <pre class="highlight"><code class="python">
# Flask-restless 0.17
data = {
    "latest_release": "3.6.1"
}
url = "http://localhost:5000/api/programming_languages/1"
headers={"Content-Type": "application/json"}

resp = requests.patch(url, simplejson.dumps(data), headers=headers)

# Print the response
&gt;&gt;&gt; resp.status_code    
200
&gt;&gt;&gt; resp.content
{
    "id": 1,
    "latest_release": "3.6.1",
    "name": "Python"
}</code></pre>
   </div>

    <div class="col-md-6 codetight">
        <pre class="highlight"><code class="python">
# Flask-restless v1.0.0
data = {
    "type": "programming_languages",
    "id": "1",
    "attributes": {
        "latest_release": "3.6.1"
    }
}
url = "http://localhost:5000/api/programming_languages/1"
headers={"Content-Type": "application/vnd.api+json"}

resp = requests.patch(url, simplejson.dumps({"data": data}), headers=headers)

# Print the response
&gt;&gt;&gt; resp.status_code
204
&gt;&gt;&gt; resp.content
b''
</code>
        </pre>
  </div>
</div>

<p>Success: We see our <code>204 - No Content</code> status code, and we expect no content to be returned from this method.</p>

<h2 id="deleteing-a-row">DELETEing a Row</h2>

<p>Good news - the request and responses are identical for the DELETE HTTP Method:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="s">"http://localhost:5000/api/programming_languages/1"</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">resp</span><span class="o">.</span><span class="n">status_code</span>
<span class="mi">204</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">resp</span><span class="o">.</span><span class="n">content</span>
<span class="n">b</span><span class="s">''</span>
</code></pre>
</div>

<h2 id="conclusion">Conclusion</h2>

<p>That wraps up our walkthrough on how to upgrade from <strong>Flask-restless v0.17</strong> to <strong>Flask-restless v1.0.0</strong>.</p>

<p>This only scratches the surface on great new features (and breaking changes) of Flask-restless v1.0.0. There are many other topics to cover, including: Resource Object Relationships, and how we make queries that handle Many-to-one, One-to-Many, and One-to-one relationships.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Twitter Dashboard w/ Flask & Tweepy</title>
	  <link>/sharrington/web-development/tweet-archiver-with-flask-and-tweepy-part-1</link>
	  <author>Sean Harrington</author>
	  <pubDate>2017-02-10T20:15:03-05:00</pubDate>
	  <guid>/sharrington/web-development/tweet-archiver-with-flask-and-tweepy-part-1</guid>
	  <description><![CDATA[
	     <h4 id="intro">Intro</h4>
<p>Flask is a versatile microframework capable of doing just about anything that you ask of it. Flask ships with <strong>Jinja2</strong> as its HTML Templating Engine, and when combined with <strong>SQLAlchemy</strong>, provides full-stack development support that rivals bulkier framework (like Django).</p>

<p>All that said, I believe Flask’s best characteristic to be its ‘microframework’ status: there are <a href="http://flask.pocoo.org/extensions/">many add-ons and extensions</a> which can be utilized “a la carte”, rather than “out of the box”. This means multiple solutions to single problems, which almost always leads to better solutions in the open-source community. The “slim” nature of the framework also makes bootstrapping projects easier, with much less boilerplate code &amp; dogmatic “best-practices”.</p>

<p>In the first step, we will use <strong>Tweepy</strong>, and Flask’s core to build a quick dashboard to view a user’s Twitter Activity. In Part II, we will explore <strong>SQLAlchemy</strong> and <strong>Flask-restless</strong> to create an API to harvest &amp; archive Tweets in a database.</p>

<p><em>I will be using Python 3.6 (faster dictionaries, default utf-8 strings, etc.), but feel free to follow along with any flavor of Python (some people don’t like to let go…)</em></p>

<h3 id="setup-our-workspace">Setup our workspace</h3>

<p><strong>Important:</strong> <em>If you don’t know what a Python virtual environment is, <a href="https://packaging.python.org/installing/#creating-virtual-environments">read about them here</a> before continuing!</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code>mkdir tweet-harvester
<span class="nb">cd </span>tweet_harvester
python -m venv env
<span class="c"># Or 'virtualenv env' to start a NEW project with OLD tools</span>
<span class="nb">source </span>env/bin/activate
mkdir tweet_harvester
touch tweet_harvester/__init__.py run.py config.py
</code></pre>
</div>

<p>Your directory structure should look like:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>tweet_harvester/
    tweet_harvester/
        __init__.py
    run.py
    config.py
    env/
</code></pre>
</div>

<h3 id="install-dependencies-with-pip">Install dependencies with pip</h3>
<div class="highlighter-rouge"><pre class="highlight"><code>pip install flask tweepy flask-restless
</code></pre>
</div>

<h3 id="hello-world-from-flask">Hello World from Flask</h3>

<ol>
  <li>Open up the <code class="highlighter-rouge">__init__.py</code> file created in step (1), entering the following content:</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span>
<span class="c"># Instantiate our app...</span>
<span class="c"># Name it the '__name__' of this module (tweet-harvest)</span>
<span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="c"># Later, we will store our Twitter tokens/keys</span>
<span class="c"># in config.py...we load our config here.</span>
<span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">from_object</span><span class="p">(</span><span class="s">'config'</span><span class="p">)</span>

<span class="c"># We define our URL route, and the controller to handle requests</span>
<span class="nd">@app.route</span><span class="p">(</span><span class="s">'/'</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">hello_world</span><span class="p">():</span>
    <span class="k">return</span> <span class="s">'&lt;h1&gt;Hello World&lt;/h1&gt;'</span>
</code></pre>
</div>

<ol start="2">
  <li>Next open the <code class="highlighter-rouge">run.py</code> file created earlier, inserting the following content:</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tweet_harvester</span> <span class="kn">import</span> <span class="n">app</span>
<span class="c"># 'app' originates from the line 'app = Flask(__name__)'</span>
<span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">port</span><span class="o">=</span><span class="mi">8080</span><span class="p">)</span>
</code></pre>
</div>

<ol start="3">
  <li>Finally, start the server</li>
</ol>

<p><strong>Important:</strong> <em>The Flask development server should <strong>never</strong> be used in Production environments, nor should <code class="highlighter-rouge">app.config['DEBUG'] == True</code> in Production. In Production, you’d want to wrap your Flask application with a WSGI server, like <a href="http://gunicorn.org/">Gunicorn</a></em></p>

<div class="highlighter-rouge"><pre class="highlight"><code>python run.py
</code></pre>
</div>
<p>…and open up your web browser to <a href="http://localhost:8080">http://localhost:8080/</a>, and verify our Hello World test.</p>

<p>Hello World with Flask is <strong>easy</strong>. Setting up and configuring a project is often one of the most difficult tasks when developing on the full-stack, as you only do it a handful of times each year (<em>think about it!</em>). Flask (<em>and Python</em>) make this hurdle an easy one to leap.</p>

<h3 id="create-a-new-twitter-application-tokens-and-keys">Create a new Twitter Application, Tokens and Keys</h3>

<ol>
  <li>Navigate to <a href="https://apps.twitter.com">https://apps.twitter.com</a>, and sign in with existing Twitter credentials, or make a new account.</li>
  <li>Click <strong>Create New App</strong> ( or just click <a href="https://apps.twitter.com/app/new">here</a> )</li>
  <li>Enter a <strong>Name</strong>, a <strong>Description</strong>, and for <strong>Website</strong> enter <em>http://foobar.com</em> (as this does not matter for the time being). Leave the <strong>Callback URL</strong> blank. Accept the developer terms, and click <strong>Create your Twitter application</strong>. <img src="/assets/images/twitter_new_application.png" alt="New Twitter Application" /></li>
  <li>On the resulting screen after app creation, navigate to the <strong>Keys and Access Tokens</strong> tab. Scroll down to <strong>Your Access Token</strong>, and click the <strong>Create my access token</strong> button. <img src="/assets/images/twitter_tokens_keys_and_secrets.jpg" alt="Twitter Access Tokens" /></li>
  <li>Once these tokens generate (should take a second or 2), you’ll want to use them in the next step.</li>
</ol>

<h3 id="deploy-our-twitter-activity-dashboard">Deploy our Twitter Activity Dashboard</h3>

<ol>
  <li>Create Twitter Environment Variables in <code class="highlighter-rouge">~/.bash_profile</code>.</li>
</ol>

<p><em>This file gets loaded every time your user account starts a new shell. For system-wide variables, enter data into <code class="highlighter-rouge">/etc/profile</code>.</em></p>

<p><em>Your <code class="highlighter-rouge">~/.bash_profile</code> <strong>or</strong> <code class="highlighter-rouge">/etc/profile</code> should contain:</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code>EXPORT <span class="nv">TWITTER_CONSUMER_KEY</span><span class="o">=</span>your_consumer_key_here
EXPORT <span class="nv">TWITTER_CONSUMER_SECRET</span><span class="o">=</span>your_consumer_secret_here
EXPORT <span class="nv">TWITTER_ACCESS_TOKEN</span><span class="o">=</span>your_access_token_here
EXPORT <span class="nv">TWITTER_ACCESS_TOKEN_SECRET</span><span class="o">=</span>your_access_token_secret_here
</code></pre>
</div>

<p><strong>IMPORTANT!</strong> After saving this file, run the following command to load your new ENV variables:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="nb">source</span> ~/.bash_profile
<span class="c"># or "source /etc/profile"</span>
</code></pre>
</div>

<ol start="2">
  <li>Load these Environment Variables into <code class="highlighter-rouge">config.py</code>:</li>
</ol>

<p><em>We want to load these from our Environment, rather than pasting the codes directly into <code class="highlighter-rouge">config.py</code> for obvious security reasons.</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>

<span class="n">DEBUG</span> <span class="o">=</span> <span class="bp">True</span> 
<span class="c"># Enable stacktrace &amp; debugger in web browser</span>
<span class="n">TWITTER_CONSUMER_KEY</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'TWITTER_CONSUMER_KEY'</span><span class="p">]</span>
<span class="n">TWITTER_CONSUMER_SECRET</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'TWITTER_CONSUMER_SECRET'</span><span class="p">]</span>
<span class="n">TWITTER_ACCESS_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'TWITTER_ACCESS_TOKEN'</span><span class="p">]</span>
<span class="n">TWITTER_ACCESS_TOKEN_SECRET</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'TWITTER_ACCESS_TOKEN_SECRET'</span><span class="p">]</span>
</code></pre>
</div>

<ol start="3">
  <li>Update <code class="highlighter-rouge">__init__.py</code> by adding Twitter authentication</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span><span class="p">,</span> <span class="n">json</span><span class="p">,</span> <span class="n">request</span>
<span class="kn">import</span> <span class="nn">tweepy</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>
<span class="c"># Load our config from an object, or module (config.py)</span>
<span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">from_object</span><span class="p">(</span><span class="s">'config'</span><span class="p">)</span>

<span class="c"># These config variables come from 'config.py'</span>
<span class="n">auth</span> <span class="o">=</span> <span class="n">tweepy</span><span class="o">.</span><span class="n">OAuthHandler</span><span class="p">(</span><span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s">'TWITTER_CONSUMER_KEY'</span><span class="p">],</span>
                           <span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s">'TWITTER_CONSUMER_SECRET'</span><span class="p">])</span>
<span class="n">auth</span><span class="o">.</span><span class="n">set_access_token</span><span class="p">(</span><span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s">'TWITTER_ACCESS_TOKEN'</span><span class="p">],</span>
                      <span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s">'TWITTER_ACCESS_TOKEN_SECRET'</span><span class="p">])</span>
<span class="n">tweepy_api</span> <span class="o">=</span> <span class="n">tweepy</span><span class="o">.</span><span class="n">API</span><span class="p">(</span><span class="n">auth</span><span class="p">)</span>

<span class="nd">@app.route</span><span class="p">(</span><span class="s">'/'</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">hello_world</span><span class="p">():</span>
    <span class="k">return</span> <span class="s">"&lt;h1&gt;Hello World&lt;/h1&gt;"</span>
</code></pre>
</div>

<ol start="4">
  <li>Define our <code class="highlighter-rouge">get_tweets()</code> function in <code class="highlighter-rouge">__init__.py</code></li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_tweets</span><span class="p">(</span><span class="n">username</span><span class="p">):</span>
    <span class="n">tweets</span> <span class="o">=</span> <span class="n">tweepy_api</span><span class="o">.</span><span class="n">user_timeline</span><span class="p">(</span><span class="n">screen_name</span><span class="o">=</span><span class="n">username</span><span class="p">)</span>                                                                            
    <span class="k">return</span> <span class="p">[{</span><span class="s">'tweet'</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
              <span class="s">'created_at'</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">created_at</span><span class="p">,</span> 
              <span class="s">'username'</span><span class="p">:</span> <span class="n">username</span><span class="p">,</span>
              <span class="s">'headshot_url'</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">user</span><span class="o">.</span><span class="n">profile_image_url</span><span class="p">}</span>
           <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">]</span>
</code></pre>
</div>

<ol start="5">
  <li>Create <code class="highlighter-rouge">templates/</code> and <code class="highlighter-rouge">tweets.html</code></li>
</ol>

<p><em>This HTML file will render the data obtained in the <code class="highlighter-rouge">get_tweets()</code> function above. Note that we load Bootstrap 4 (alpha-release) from maxcdn.</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c">&lt;!-- templates/tweets.html --&gt;</span>  
<span class="nt">&lt;html</span> <span class="na">lang=</span><span class="s">"en"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;head&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">charset=</span><span class="s">"utf-8"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">name=</span><span class="s">"viewport"</span> <span class="na">content=</span><span class="s">"width=device-width, initial-scale=1, shrink-to-fit=no"</span><span class="nt">&gt;</span>

    <span class="nt">&lt;title&gt;</span>Tweet Harvester<span class="nt">&lt;/title&gt;</span>

    <span class="c">&lt;!-- Bootstrap 4 Stuff https://v4-alpha.getbootstrap.com/  --&gt;</span> 
    <span class="nt">&lt;link</span> <span class="na">rel=</span><span class="s">"stylesheet"</span>
          <span class="na">href=</span><span class="s">"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css"</span>
          <span class="na">integrity=</span><span class="s">"sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ"</span>
          <span class="na">crossorigin=</span><span class="s">"anonymous"</span><span class="nt">&gt;</span>
    <span class="c">&lt;!-- End Bootstrap 4 stuff --&gt;</span>
  <span class="nt">&lt;/head&gt;</span>
  <span class="nt">&lt;body&gt;</span>
    <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"container"</span><span class="nt">&gt;</span>
      <span class="nt">&lt;h1</span> <span class="na">class=</span><span class="s">"p-3"</span><span class="nt">&gt;</span>Tweet Harvester<span class="nt">&lt;/h1&gt;</span>
      {% for tweet in tweets %}
      <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"list-group"</span><span class="nt">&gt;</span>
         <span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"#"</span> <span class="na">class=</span><span class="s">"list-group-item list-group-item-action flex-column align-items-start"</span><span class="nt">&gt;</span>
           <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"d-flex w-100 justify-content-between"</span><span class="nt">&gt;</span>
             <span class="nt">&lt;img</span> <span class="na">src=</span><span class="s">"{{tweet.headshot_url}}"</span> <span class="na">class=</span><span class="s">"w-12 p-1 float-left image-thumbnail"</span><span class="nt">&gt;</span>  
             <span class="nt">&lt;h5</span> <span class="na">class=</span><span class="s">"ml-10 w-75 mb-1"</span><span class="nt">&gt;</span>{{ tweet.tweet }}<span class="nt">&lt;/h5&gt;</span>
             <span class="nt">&lt;small&gt;</span>{{ tweet.created_at }}<span class="nt">&lt;/small&gt;</span>
           <span class="nt">&lt;/div&gt;</span>
         <span class="nt">&lt;/a&gt;</span>
      <span class="nt">&lt;/div&gt;</span>
      {% endfor %}
      
    <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;/body&gt;</span>
<span class="nt">&lt;/html&gt;</span>
</code></pre>
</div>

<p>Your directory structure should look like:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>tweet_harvester/
    tweet_harvester/
        __init__.py
        templates/
            tweets.html
    run.py
    config.py
    env/
</code></pre>
</div>

<ol start="6">
  <li>Add <strong>route</strong> and <strong>controller</strong> to <code class="highlighter-rouge">__init__.py</code> to render this template</li>
</ol>

<p><em>We get the <code class="highlighter-rouge">username</code> parameter below directly from the URL with the <code class="highlighter-rouge">/&lt;string:username&gt;</code> segment of our route’s URL. We then pass it to the <code class="highlighter-rouge">tweets(username)</code> function.</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="nd">@app.route</span><span class="p">(</span><span class="s">'/tweet-harvester/&lt;string:username&gt;'</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tweets</span><span class="p">(</span><span class="n">username</span><span class="p">):</span>
  <span class="c"># 'tweets' is passed as a keyword-arg (**kwargs)</span>
  <span class="c"># **kwargs are bound to the 'tweets.html' Jinja Template context</span>
  <span class="k">return</span> <span class="n">render_template</span><span class="p">(</span><span class="s">"tweets.html"</span><span class="p">,</span> <span class="n">tweets</span><span class="o">=</span><span class="n">get_tweets</span><span class="p">(</span><span class="n">username</span><span class="p">))</span>
</code></pre>
</div>
<p><em>Flask leverages the Jinja2 Templating Engine. In our Flask controller, we return with:</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">return</span> <span class="n">render_template</span><span class="p">(</span><span class="n">foo</span><span class="o">.</span><span class="n">html</span><span class="p">,</span> <span class="n">var1</span><span class="o">=</span><span class="n">obj1</span><span class="p">,</span> <span class="n">var2</span><span class="o">=</span><span class="n">obj2</span><span class="p">,</span> <span class="n">varN</span><span class="o">=</span><span class="n">objN</span><span class="p">)</span>
</code></pre>
</div>

<p><em>…with an infinite number of <code class="highlighter-rouge">var=obj</code> bindings. These bindings are <a href="http://stackoverflow.com/questions/1769403/understanding-kwargs-in-python">passed via <strong>**kwargs</strong></a> to create the template’s <strong>context</strong>. This Jinja <strong>context</strong> is available anywhere within a Jinja <strong>block</strong>, where we can embed Python to modify/render values.</em></p>

<p><em>An <strong>example Jinja for-loop block</strong> is as follows:</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code>
<span class="nt">&lt;ul&gt;</span>
  {% for elem in var1 %}
  <span class="nt">&lt;li&gt;</span>{{elem}}<span class="nt">&lt;/li&gt;</span>
  {% endfor %} )
<span class="nt">&lt;/ul&gt;</span>

</code></pre>
</div>
<p><em>…which would render a list-item <strong>&lt;li&gt;</strong> for each <strong>elem</strong> in the <strong>list</strong> bound to <strong>var1</strong>.</em></p>

<ol start="6">
  <li>Start your server, and test with any Twitter handle</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code>python run.py
</code></pre>
</div>
<p><em>Navigate to <a href="http://localhost:8080/tweet-harvester/realDonaldTrump#">http://localhost:8080/tweet-harvester/realDonaldTrump</a> to test!</em></p>

<hr />

<h4 id="success">Success!</h4>

<p>You’ve succesfully deployed a simple Twitter Activity dashboard, and have gotten your hands dirty with some of Flask’s core features and concepts, namely:</p>

<ol>
  <li>Jinja2</li>
  <li>Flask Routes &amp; Controllers (Views)</li>
  <li>Flask Project Structure</li>
  <li>Starting the Flask Development Server</li>
</ol>


	  ]]></description>
	</item>

	<item>
	  <title>Connecting to SQL Server from SQLAlchemy on a Mac</title>
	  <link>/sharrington/databases/connecting-to-sql-server-with-sqlalchemy</link>
	  <author>Sean Harrington</author>
	  <pubDate>2017-01-03T00:05:00-05:00</pubDate>
	  <guid>/sharrington/databases/connecting-to-sql-server-with-sqlalchemy</guid>
	  <description><![CDATA[
	     <p><em>This post explains how to connect to SQL Server using SQLAlchemy, pyodbc, UnixODBC and FreeTDS on a Mac</em></p>

<h3>Install UnixODBC &amp; FreeTDS</h3>

<ol>
  <li>Install via Homebrew
    <div class="highlighter-rouge"><pre class="highlight"><code>brew install unixodbc
brew install freetds --with-unixodbc
</code></pre>
    </div>
  </li>
  <li>Test with FreeTDS from terminal
    <div class="highlighter-rouge"><pre class="highlight"><code>tsql -S <span class="o">[</span>IP or Hostname] -U <span class="o">[</span>username] -P <span class="o">[</span>password]
locale is <span class="s2">"en_US.UTF-8"</span>
locale charset is <span class="s2">"UTF-8"</span>
using default charset <span class="s2">"UTF-8"</span>
1&gt;
</code></pre>
    </div>
  </li>
</ol>

<h3>Configure odbc.ini &amp; odbcinst.ini</h3>

<ol>
  <li>Open /usr/local/etc/odbcinst.ini, point to the driver at libtdsodbc.so&lt;/h3&gt;
    <div class="highlighter-rouge"><pre class="highlight"><code><span class="o">[</span>FreeTDS]
Driver <span class="o">=</span> /usr/local/lib/libtdsodbc.so
Setup <span class="o">=</span> /usr/local/lib/libtdsodbc.so
FileUsage <span class="o">=</span> 1
</code></pre>
    </div>
  </li>
  <li>Open /usr/local/etc/odbc.ini and create new DSN
    <div class="highlighter-rouge"><pre class="highlight"><code><span class="o">[</span>MSSQL_DSN]
<span class="nv">Driver</span><span class="o">=</span>FreeTDS
<span class="nv">Server</span><span class="o">=</span>10.110.0.200
<span class="nv">Port</span><span class="o">=</span>1433
<span class="nv">Database</span><span class="o">=</span>my_database_name
</code></pre>
    </div>
  </li>
  <li>Test the DSN
    <div class="highlighter-rouge"><pre class="highlight"><code>isql MSSQL_DSN username password -v
+---------------------------------------+
| Connected!                            |
|                                       |
| sql-statement                         |
| <span class="nb">help</span> <span class="o">[</span>tablename]                      |
| quit                                  |
|                                       |
+---------------------------------------+
<span class="gp">SQL&gt; </span>^D
</code></pre>
    </div>
  </li>
</ol>

<h3>Install pyodbc</h3>
<div class="highlighter-rouge"><pre class="highlight"><code>pip install pyodbc
</code></pre>
</div>

<h3>Connect with sqlalchemy</h3>
<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="n">create_engine</span>

<span class="n">e</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="s">"mssql+pyodbc://username:password@MSSQL_DSN"</span><span class="p">)</span>
</code></pre>
</div>

<p>Hopefully you can quickly get connected to your SQL Server instance via Python with the steps above. For me, it has been notoriously more difficult to connect to than other databases like MySQL and PostgreSQL. In fact, I built an open-sourced tool to migrate an entire database (or a handful of tables) from SQL Server, to any other RDBMS like MySQL.</p>

<p><a href="https://github.com/seanharr11/etlalchemy">Check out etlalchemy here on github</a></p>

<hr />

<h4>A couple of notes...</h4>

<ol>
  <li>Depending on the SQL Server version you are connecting to, you may need to specify a TDS Protocol Version in <em>/usr/local/etc/freetds.conf</em>:
    <div class="highlighter-rouge"><pre class="highlight"><code><span class="o">[</span>global]
    <span class="c"># Uncomment below to guess protocol</span>
    <span class="c"># tds version = auto</span>
    tds version <span class="o">=</span> 7.3
</code></pre>
    </div>
  </li>
</ol>

<p><strong>Full Compatability Matrix</strong> (from <a href="http://www.freetds.org/userguide/choosingtdsprotocol.htm">http://freetds.org</a>)</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Product</th>
      <th style="text-align: left">TDS Version</th>
      <th style="text-align: left">Comment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">Sybase before System 10, Microsoft SQL Server 6.x</td>
      <td style="text-align: left">4.2</td>
      <td style="text-align: left">Still works with all products, subject to its limitations.</td>
    </tr>
    <tr>
      <td style="text-align: left">Sybase System 10 and above</td>
      <td style="text-align: left">5.0</td>
      <td style="text-align: left">Still the most current protocol used by Sybase.</td>
    </tr>
    <tr>
      <td style="text-align: left">Sybase System SQL Anywhere</td>
      <td style="text-align: left">5.0 <em>only</em></td>
      <td style="text-align: left">Originally Watcom SQL Server, a completely separate codebase. Our best information is that SQL Anywhere first supported TDS in version 5.5.03 using the OpenServer Gateway (OSG), and native TDS 5.0 support arrived with version 6.0.</td>
    </tr>
    <tr>
      <td style="text-align: left">Microsoft SQL Server 7.0</td>
      <td style="text-align: left">7.0</td>
      <td style="text-align: left">Includes support for the extended datatypes in SQL Server 7.0 (such as char/varchar fields of more than 255 characters), and support for Unicode.</td>
    </tr>
    <tr>
      <td style="text-align: left">Microsoft SQL Server 2000</td>
      <td style="text-align: left">7.1</td>
      <td style="text-align: left">Include support for bigint (64 bit integers), variant and collation on all fields. Collation is not widely used.</td>
    </tr>
    <tr>
      <td style="text-align: left">Microsoft SQL Server 2005</td>
      <td style="text-align: left">7.2</td>
      <td style="text-align: left">Includes support for varchar(max), varbinary(max), xml datatypes and MARS[a].</td>
    </tr>
    <tr>
      <td style="text-align: left">Microsoft SQL Server 2008</td>
      <td style="text-align: left">7.3</td>
      <td style="text-align: left">Includes support for time, date, datetime2, datetimeoffset.</td>
    </tr>
    <tr>
      <td style="text-align: left">Microsoft SQL Server 2012 or 2014</td>
      <td style="text-align: left">7.4</td>
      <td style="text-align: left">Includes support for session recovery.</td>
    </tr>
    <tr>
      <td style="text-align: left">N/A</td>
      <td style="text-align: left">8.0</td>
      <td style="text-align: left">FreeTDS will alias this version to 7.1 for backwards compatibility reasons, but this should be avoided due to future compatibility concerns. See note below on obsolete versions.</td>
    </tr>
  </tbody>
</table>


	  ]]></description>
	</item>

	<item>
	  <title>REST API with Flask-Restless and SQLAlchemy</title>
	  <link>/sharrington/web-development/sqlalchemy-defined-rest-api</link>
	  <author>Sean Harrington</author>
	  <pubDate>2016-08-19T02:32:00-04:00</pubDate>
	  <guid>/sharrington/web-development/sqlalchemy-defined-rest-api</guid>
	  <description><![CDATA[
	     <p>This post shows how to auto-generate a REST API from a handful of SQLAlchemy models. This means full CRUD <em>(POST, GET, PUT, DELETE)</em> endpoint generation for each SQLAlchemy model defined.</p>

<p>Let’s say our company is building a Single-Page Application for librarians &amp; readers that accomplishes the following 2 goals:</p>

<ol>
  <li>Show the availability and information of a given book to readers.</li>
  <li>Allow a librarian to perform CRUD operations to update their libary’s inventory.</li>
</ol>

<p>We’ve been tasked with building a REST API to allow a Single-Page Application to interface with our database.</p>

<h4 id="environment-setup">Environment Setup</h4>
<ol>
  <li>Create project root directory.
    <div class="highlighter-rouge"><pre class="highlight"><code>mkdir automagic_api
</code></pre>
    </div>
  </li>
  <li>Create and activate virtualenv.
    <div class="highlighter-rouge"><pre class="highlight"><code>cd automagic_api;
# virtualenv env; Python 2.7
python -m venv env
source env/bin/activate
</code></pre>
    </div>
  </li>
  <li>Install flask-restless and sqlalchemy
    <div class="highlighter-rouge"><pre class="highlight"><code>pip install flask-restless sqlalchemy
</code></pre>
    </div>
  </li>
</ol>

<p>Your project directory tree should look as follows:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>automagic_api/
env/
</code></pre>
</div>

<h4 id="further-compartmentalize-the-project-and-define-our-models">Further compartmentalize the project and define our models</h4>

<ol>
  <li>Create nested project directory ‘/automagic_api’ to hold Flask-specific files.
    <div class="highlighter-rouge"><pre class="highlight"><code>mkdir automagic_api
cd automagic_api
</code></pre>
    </div>
  </li>
  <li>Create <strong>‘models.py’</strong> within the flask-project directory and define <strong>Book</strong> and <strong>Author</strong>..</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sqlalchemy.ext.declarative</span> <span class="kn">import</span> <span class="n">declarative_base</span><span class="p">,</span> <span class="n">declared_attr</span>
<span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="n">ForeignKey</span><span class="p">,</span> <span class="n">Column</span><span class="p">,</span> <span class="n">Integer</span><span class="p">,</span> <span class="n">String</span><span class="p">,</span> <span class="n">Boolean</span>
<span class="kn">from</span> <span class="nn">sqlalchemy.orm</span> <span class="kn">import</span> <span class="n">backref</span><span class="p">,</span> <span class="n">relationship</span>
<span class="kn">from</span> <span class="nn">automagic_api</span> <span class="kn">import</span> <span class="n">Base</span>

<span class="k">class</span> <span class="nc">Author</span><span class="p">(</span><span class="n">Base</span><span class="p">):</span>
    <span class="nd">@declared_attr</span>
    <span class="k">def</span> <span class="nf">__tablename__</span><span class="p">(</span><span class="n">cls</span><span class="p">):</span>
        <span class="c"># API endpoint will take the form '/api/__tablename__'</span>
        <span class="k">return</span> <span class="n">cls</span><span class="o">.</span><span class="n">__name__</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="nb">id</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">Integer</span><span class="p">,</span> <span class="n">primary_key</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> 
    <span class="n">first_name</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">String</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>
    <span class="n">last_name</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">String</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">Book</span><span class="p">(</span><span class="n">Base</span><span class="p">):</span>
    <span class="nd">@declared_attr</span>
    <span class="k">def</span> <span class="nf">__tablename__</span><span class="p">(</span><span class="n">cls</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">cls</span><span class="o">.</span><span class="n">__name__</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="nb">id</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">Integer</span><span class="p">,</span> <span class="n">primary_key</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> 
    <span class="n">title</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">String</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>
    <span class="n">author_id</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">Integer</span><span class="p">,</span> 
        <span class="n">ForeignKey</span><span class="p">(</span><span class="s">"author.id"</span><span class="p">),</span> <span class="n">nullable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">author</span> <span class="o">=</span> <span class="n">relationship</span><span class="p">(</span><span class="n">Author</span><span class="p">,</span> 
        <span class="n">backref</span><span class="o">=</span><span class="n">backref</span><span class="p">(</span><span class="s">'books'</span><span class="p">))</span>  
    <span class="n">is_available</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">Boolean</span><span class="p">)</span>


</code></pre>
</div>

<p>Your directory structure should now look like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>automagic_api/
   automagic_api/
       models.py
   env/
</code></pre>
</div>

<h4 id="create-controllerspy-to-define-endpoints">Create controllers.py to define endpoints</h4>

<p>Below we define our 2 <a href="http://flask-restless.readthedocs.io/en/stable/basicusage.html">Flask-restless API blueprints</a>: one for <strong>Book</strong> and one for <strong>Author</strong>, which when instantiated, construct the CRUD endpoints for each respective model.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">automagic_api</span> <span class="kn">import</span> <span class="n">app</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">manager</span>
<span class="kn">from</span> <span class="nn">automagic_api.models</span>\
    <span class="kn">import</span> <span class="n">Book</span><span class="p">,</span> <span class="n">Author</span>

<span class="n">author_api_blueprint</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">create_api_blueprint</span><span class="p">(</span><span class="n">Author</span><span class="p">,</span>
        <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">'GET'</span><span class="p">,</span> <span class="s">'PATCH'</span><span class="p">,</span> <span class="s">'POST'</span><span class="p">,</span> <span class="s">'DELETE'</span><span class="p">])</span>
<span class="n">book_api_blueprint</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">create_api_blueprint</span><span class="p">(</span><span class="n">Book</span><span class="p">,</span>
        <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">'GET'</span><span class="p">,</span> <span class="s">'PATCH'</span><span class="p">,</span> <span class="s">'POST'</span><span class="p">,</span> <span class="s">'DELETE'</span><span class="p">])</span>

</code></pre>
</div>

<h4 id="your-directory-should-now-look-like">Your directory should now look like:</h4>

<div class="highlighter-rouge"><pre class="highlight"><code>automagic_api/
   automagic_api/
       models.py
       controllers.py
   env/
</code></pre>
</div>

<h4 id="create-initpy-in-our-flask-project">Create __init__.py in our Flask-project</h4>

<p>Create the file in <strong>‘automagic_api/automagic_api/’</strong>. This file will import our <strong>models.py</strong>, our <strong>controllers.py</strong> and instantiate our API.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">flask</span>
<span class="kn">import</span> <span class="nn">flask_restless</span>
<span class="kn">from</span> <span class="nn">sqlalchemy.ext.declarative</span> <span class="kn">import</span> <span class="n">declarative_base</span><span class="p">,</span> <span class="n">declared_attr</span>
<span class="kn">from</span> <span class="nn">sqlalchemy.orm</span> <span class="kn">import</span> <span class="n">sessionmaker</span><span class="p">,</span> <span class="n">scoped_session</span>
<span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">flask</span><span class="o">.</span><span class="n">Flask</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="c"># Create our SQLAlchemy DB engine</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="s">'sqlite:///foobar.db'</span><span class="p">)</span>
<span class="n">Session</span> <span class="o">=</span> <span class="n">sessionmaker</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">engine</span><span class="p">,</span> <span class="n">autocommit</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">autoflush</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">scoped_session</span><span class="p">(</span><span class="n">Session</span><span class="p">)</span>

<span class="n">Base</span> <span class="o">=</span> <span class="n">declarative_base</span><span class="p">()</span>
<span class="n">Base</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">bind</span> <span class="o">=</span> <span class="n">engine</span>

<span class="c"># Import all models to add them to Base.metadata</span>
<span class="kn">from</span> <span class="nn">models</span> <span class="kn">import</span> <span class="n">Book</span><span class="p">,</span> <span class="n">Author</span>

<span class="n">Base</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">create_all</span><span class="p">()</span>

<span class="n">manager</span> <span class="o">=</span> <span class="n">flask_restless</span><span class="o">.</span><span class="n">APIManager</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
<span class="c"># Register flask-restless blueprints to instantiate CRUD endpoints</span>
<span class="kn">from</span> <span class="nn">controllers</span> <span class="kn">import</span> <span class="n">book_api_blueprint</span><span class="p">,</span> <span class="n">author_api_blueprint</span>
<span class="n">app</span><span class="o">.</span><span class="n">register_blueprint</span><span class="p">(</span><span class="n">author_api_blueprint</span><span class="p">)</span>
<span class="n">app</span><span class="o">.</span><span class="n">register_blueprint</span><span class="p">(</span><span class="n">book_api_blueprint</span><span class="p">)</span>
</code></pre>
</div>

<h4 id="create-runpy">Create run.py</h4>

<p>Create <strong>run.py</strong> in our root directory</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">automagic_api</span> <span class="kn">import</span> <span class="n">app</span>
<span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">debug</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><span class="s">'0.0.0.0'</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
</code></pre>
</div>

<h4 id="your-final-directory-structure-should-look-as-follows">Your final directory structure should look as follows:</h4>

<div class="highlighter-rouge"><pre class="highlight"><code>automagic_api/
   run.py
   automagic_api/
       __init__.py
       models.py
       controllers.py
   env/
</code></pre>
</div>

<h4 id="start-and-test-your-api">Start and test your API!</h4>

<p>In the project root, start the server</p>

<div class="highlighter-rouge"><pre class="highlight"><code>env/bin/python run.py
</code></pre>
</div>

<p>In a python CLI, create a POST request to create a new <strong>Book</strong>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">requests</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">json</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span> 
    <span class="s">'title'</span><span class="p">:</span> <span class="s">"The Eye of the World"</span><span class="p">,</span>
    <span class="s">'author'</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">'first_name'</span><span class="p">:</span> <span class="s">"Robert"</span><span class="p">,</span>
        <span class="s">'last_name'</span><span class="p">:</span> <span class="s">"Jordan"</span>
        <span class="p">},</span>  
    <span class="s">'is_available'</span><span class="p">:</span> <span class="bp">True</span>
<span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s">'content-type'</span><span class="p">:</span> <span class="s">'application/json'</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s">"http://localhost:5000/api/book"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">),</span><span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span>
<span class="mi">201</span>
</code></pre>
</div>

<p>Go ahead and open up a web browser, and navigate to <a href="http://localhost:5000/api/book">http://localhost:5000/api/book</a> to see the <em>Book</em> object that you just POSTed to your sqlite database.</p>

<p>Likewise, you can invert this request and check out <a href="http://localhost:5000/api/author">http://localhost:5000/api/author</a> to see the <em>Author</em> object that was created, and the nested <em>“books”</em> attribute that the author has written.</p>

<ul>
  <li><em><strong>Note</strong>: URLs for the API are constructed based off of the <strong>__tablename__</strong> of the sqlalchemy model, and are prefixed with “/api” (i.e Book -&gt; “/api/book”)</em></li>
</ul>

<p>Congratulations, you now have a working boilerplate for a SQLAlchemy-model defined REST API. Now go ahead and add more models and endpoints!</p>

<h4 id="final-remarks">Final Remarks</h4>

<p>The reason that I use Flask-restless for day-to-day APIs is it’s abstraction.</p>

<ol>
  <li>It preserves abstraction between the database’s relational model, and the JSON schema expected as input and output to the API</li>
  <li>It preserves abstraction between SQLAlchemy, and the SQL dialect under-the-hood.</li>
</ol>

<p>For instance, when I POST the following payload from a client application, I don’t care about the relational model between an <strong>Author</strong> and a <strong>Book</strong>, I just care that the JSON <strong>Book</strong> object contains a nested <strong>Author</strong> in its schema. By providing the nested <strong>Author</strong> object <em>WITHOUT</em> an <strong>id</strong> field, I implicitly CREATE this Author in the database.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="p">{</span> 
    <span class="s1">'title'</span><span class="err">:</span> <span class="s2">"The Eye of the World"</span><span class="p">,</span>
    <span class="s1">'author'</span><span class="err">:</span> <span class="p">{</span>
        <span class="s1">'first_name'</span><span class="err">:</span> <span class="s2">"Robert"</span><span class="p">,</span>
        <span class="s1">'last_name'</span><span class="err">:</span> <span class="s2">"Jordan"</span>
        <span class="p">},</span>  
    <span class="s1">'is_available'</span><span class="err">:</span> <span class="nx">True</span>
<span class="p">}</span>
</code></pre>
</div>

<p>Conversely, if I would like to create a book that references a pre-existing author, I would changed my nested <strong>Author</strong> object to contain the <strong>id</strong> of the <strong>Author</strong> who wrote it.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="p">{</span> 
    <span class="s1">'title'</span><span class="err">:</span> <span class="s2">"The Eye of the World"</span><span class="p">,</span>
    <span class="s1">'author'</span><span class="err">:</span> <span class="p">{</span>
         <span class="s1">'id'</span><span class="err">:</span> <span class="mi">1</span>   
     <span class="p">},</span>
     <span class="c1">// or, we could break abstraction and assign an 'author_id':</span>
     <span class="c1">// 'author_id': 1,</span>
    <span class="s1">'is_available'</span><span class="err">:</span> <span class="nx">True</span>
<span class="p">}</span>
</code></pre>
</div>

<p>Regarding preservation of SQLAlchemy’s level of abstraction, Flask-restless goes as far as to implement SQLAlchemy’s <a href="http://docs.sqlalchemy.org/en/latest/orm/query.html">Query API</a> at the REST API level. Take the following example:</p>

<p>If Robert Jordan wrote 14 books (which he did in a painstakingly long series), and I only wanted to grab all books that Robert Jordan penned which are <strong>available</strong> in the library I could run the following query:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>http://localhost:5000/api/book?q={"filters":[{"name":"is_available","op":"==","val":true},{"name":"author_id","op":"==","val":1}]}
</code></pre>
</div>

<p>This would return our targeted books, and translates to running the following in SQLAlchemy:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">session</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">Book</span><span class="p">)</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">Book</span><span class="o">.</span><span class="n">author_id</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">Book</span><span class="o">.</span><span class="n">is_available</span> <span class="o">==</span> <span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="nb">all</span><span class="p">()</span>
</code></pre>
</div>

<ul>
  <li>The searchformat API also implements <em>order_by</em>, <em>limit</em>, <em>offset</em> and <em>group_by</em>. <br /><a href="http://flask-restless.readthedocs.io/en/stable/searchformat.html">See Flask-restless searchformat</a></li>
</ul>

<p>These 2 key features make this tool perfect for Single-Page Applications that need to communicate with an API server.</p>

<p><em>A huge thanks to the brilliant developers of Flask, Flask-restless and SQLAlchemy. I am but a humble messenger spreading the work of others…</em></p>


	  ]]></description>
	</item>

	<item>
	  <title>Installing cx_Oracle Driver on El Capitan</title>
	  <link>/sharrington/databases/oracle/install-cx_oracle-mac</link>
	  <author>Sean Harrington</author>
	  <pubDate>2016-07-14T01:05:00-04:00</pubDate>
	  <guid>/sharrington/databases/oracle/install-cx_oracle-mac</guid>
	  <description><![CDATA[
	     <h5 id="download-oracle-instantclient">Download Oracle instantclient</h5>
<ol>
  <li>Navigate to the <a href="http://www.oracle.com/technetwork/topics/intel-macsoft-096467.html">‘Oracle Instant Client Downloads’</a> page.</li>
  <li>Download <strong>instantclient-basic-macos.x64-12.1.0.2.0.zip</strong> and <strong>instantclient-sdk-macos.x64-12.1.0.2.0.zip</strong>
    <ul>
      <li>You will need an Oracle account to proceed with the download.</li>
    </ul>
  </li>
  <li>Enter the ‘~/Downloads’ folder in Terminal, and unzip both downloads:</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="nb">cd</span> ~/Downloads
<span class="c"># Or 'cd &lt;download_directory&gt;'</span>
unzip instantclient-basic-macos.x64-12.1.0.2.0.zip
<span class="c"># Running the below 'unzip' command will automagically </span>
<span class="c"># place the unzipped contents in 'instantclient_12_1/sdk'</span>
unzip instantclient-sdk-macos.x64-12.1.0.2.0.zip
</code></pre>
</div>

<h5 id="move-directory-and-link-libclntshdylib121">Move directory and link libclntsh.dylib.12.1</h5>

<div class="highlighter-rouge"><pre class="highlight"><code>mv instantclient_12_1 /usr/local/opt/instantclient_12_1
<span class="nb">cd</span> /usr/local/opt/instantclient_12_1
ln -s libclntsh.dylib.12.1 libclntsh.dylib
</code></pre>
</div>

<h5 id="configure-environment-variables">Configure environment variables</h5>

<div class="highlighter-rouge"><pre class="highlight"><code># Tell cx_Oracle setup.py where to find instantclient libs
export ORACLE_HOME=/usr/local/opt/instantclient_12_1
# Set -rpath option to tell gcc to look in ORACLE_HOME when linking
export FORCE_RPATH=1

</code></pre>
</div>

<h5 id="download-and-install-cxoracle">Download and install cx_Oracle</h5>

<div class="highlighter-rouge"><pre class="highlight"><code># Install with pip
pip install cx_Oracle
</code></pre>
</div>

<h5 id="verify-cxoracle-was-correctly-installed">Verify cx_Oracle was correctly installed</h5>

<div class="highlighter-rouge"><pre class="highlight"><code>python -c "import cx_Oracle"
</code></pre>
</div>

<p>If this fails then you may see the following exception:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
ImportError: dlopen(/Library/Python/2.7/site-packages/cx_Oracle.so, 2): Library not loaded: @rpath/libclntsh.dylib.12.1
  Referenced from: /Library/Python/2.7/site-packages/cx_Oracle.so
  Reason: image not found
</code></pre>
</div>

<p>If you are seeing this exception, you either skipped setting <code class="highlighter-rouge">ORACLE_HOME</code> and <code class="highlighter-rouge">FORCE_RPATH</code> (as described above), or you are using a cached version of the cx_Oracle build when installing. To force pip to re-build the package, run:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>pip install --no-cache-dir --allow-external --allow-unverified cx_oracle
</code></pre>
</div>

<p><em>Thanks to <a href="http://stackoverflow.com/users/4799035/christopher-jones">Christopher Jones</a> for help simplifying the above steps.</em></p>


	  ]]></description>
	</item>

	<item>
	  <title>Migrating Between Relational Databases</title>
	  <link>/sharrington/databases/migrating-between-databases-with-etlalchemy</link>
	  <author>Sean Harrington</author>
	  <pubDate>2016-07-14T01:05:00-04:00</pubDate>
	  <guid>/sharrington/databases/migrating-between-databases-with-etlalchemy</guid>
	  <description><![CDATA[
	     <p><br />
In this post we show how to migrate off of any RDBMS, onto any other RDBMS. We use a case study of Oracle -&gt; MySQL, but we can move between any 2 combinations (SQL Server -&gt; Postgres, MySQL -&gt; SQLite…etc.)</p>

<p style="text-align: center"><a href="#code-snippet">TL;DR? Jump to code snippet solution.</a></p>

<h3 id="the-new-england-patriots-case-study">The New England Patriots Case Study</h3>

<p>With NEP, I was responsible for projects spanning various fields, ranging from Web Development to Machine Learning. After learning that we kept the majority of our data in an <strong>Oracle 9i</strong> RDBMS, and learning that Oracle pulled support for the system in July 2010, naturally the first move to make was to migrate onto a different RDBMS, or to upgrade.</p>

<p>In short, we chose to migrate from <strong>Oracle onto MySQL</strong> as our target RDBMS. So began my journey to migrate off of a <strong>very outdated</strong> database, and onto a modern solution.</p>

<h3 id="the-project-requirements">The Project Requirements</h3>

<p>As most projects do, the project grew from a simple database migration, to a database migration requiring cleaning data, altering schema, identifying and dropping unused/legacy columns etc… We identified the following requirements when searching for a solution:</p>

<ol>
  <li><strong>No Loss of Information</strong>
    <ul>
      <li><em>Data, schema, constraints and indexes all must be migrated without any loss of information.</em></li>
    </ul>
  </li>
  <li><strong>Automated Solution</strong>
    <ul>
      <li><em>Avoid .sql scripts and manual scripting.</em></li>
      <li><em>‘Push-button’ solution, rather than several small procedures.</em></li>
    </ul>
  </li>
  <li><strong>High Degree of Customizability.</strong>
    <ul>
      <li><em>Adding custom rules for schema transformations.</em></li>
      <li><em>Adding custom rules for data transformations.</em></li>
    </ul>
  </li>
  <li><strong>Performance</strong>
    <ul>
      <li><em>Fast enough to test multiple runs per day.</em></li>
    </ul>
  </li>
</ol>

<h3 id="the-immediate-solutions-failed">The Immediate Solutions Failed…</h3>

<ol>
  <li><strong>MySQL Workbench</strong> involved a great deal of manual configuring, and no ‘automated’ way to migrate from Oracle -&gt; MySQL.
    <ul>
      <li>(Why would Oracle allow Enterprise -&gt; Open-source migrations within their own product-line anyway?)</li>
    </ul>
  </li>
  <li><strong>DBConvert</strong> lacked support for Oracle versions before 10.x.x.
    <ul>
      <li>(Pricing also starts at $150 for Personal use, $1000 for Enterprise use)</li>
    </ul>
  </li>
  <li>A few Ruby gems (taps) lacked support for many of the Oracle column types, and the cx_Oracle driver in general.</li>
</ol>

<h3 id="the-solution">The Solution</h3>

<p>I decided to dust off an old college project, burn the midnight oil to revitalize it, and leverage it to solve this problem.</p>

<p id="code-snippet"></p>
<p>The project, <a href="https://github.com/seanharr11/etlalchemy" title="Navigate to etlalchemy github page"><strong>etlalchemy</strong></a>, is an open-sourced Python application which sits atop <a href="http://www.sqlalchemy.org/" title="Navigate to sqlalchemy.org"><strong>SQLAlchemy</strong></a>, and allows ETL (Extract, Transform, Load) functionality between any 2 SQL databases. The tool presents a <a href="https://www.python.org/dev/peps/pep-0020/#the-zen-of-python"><em>“Simple over Complex”</em></a> solution to the problem, allowing you to <em>Migrate any SQL Database with 4 Lines of Code</em>. (More advanced features are also available).</p>

<p><strong>To install the tool:</strong></p>

<div class="highlighter-rouge"><pre class="highlight"><code>pip install etlalchemy
<span class="c"># On El Capitan:</span>
<span class="c">### pip install --ignore-installed etlalchemy</span>
</code></pre>
</div>

<p><strong>To run the tool:</strong></p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">etlalchemy</span> <span class="kn">import</span> <span class="n">ETLAlchemySource</span><span class="p">,</span> <span class="n">ETLAlchemyTarget</span>
<span class="c"># Migrate from SQL Server onto PostgreSQL</span>
<span class="n">src</span> <span class="o">=</span> <span class="n">ETLAlchemySource</span><span class="p">(</span><span class="s">"mssql+pyodbc://user:passwd@DSN_NAME"</span><span class="p">)</span>
<span class="n">tgt</span> <span class="o">=</span> <span class="n">ETLAlchemyTarget</span><span class="p">(</span><span class="s">"postgresql://user:passwd@hostname/dbname"</span><span class="p">,</span>
                          <span class="n">drop_database</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tgt</span><span class="o">.</span><span class="n">addSource</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
<span class="n">tgt</span><span class="o">.</span><span class="n">migrate</span><span class="p">()</span>
</code></pre>
</div>

<p>Since solving my problem with the first pass of etlalchemy, I have spent months adding support for PostgreSQL, MySQL, Oracle, SQL Server, and SQLite. This means that with 4 lines of code, you can do things like migrate from SQL Server onto MySQL, migrate from Oracle onto PostgreSQL, or in my case migrate Oracle onto MySQL. Another helpful usecase is to migrate a remote MySQL database onto a local SQLite database to test an application on your local machine.</p>

<p>Happy Database Migrating!</p>

	  ]]></description>
	</item>


</channel>
</rss>
